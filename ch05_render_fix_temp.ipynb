{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {
    "id": "45398736-7e89-4263-89c8-92153baff553"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chHu_JbUfOuJ",
   "metadata": {
    "id": "chHu_JbUfOuJ"
   },
   "source": [
    "# **Building LLM from scratch**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v0qnjsRDykXB",
   "metadata": {
    "id": "v0qnjsRDykXB"
   },
   "source": [
    "##**Chapter 2: Working with text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gtdpHSuiyvTk",
   "metadata": {
    "id": "gtdpHSuiyvTk"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "GsDLg7wXA07j",
   "metadata": {
    "id": "GsDLg7wXA07j"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vS0wu-Q2yvnU",
   "metadata": {
    "id": "vS0wu-Q2yvnU"
   },
   "outputs": [],
   "source": [
    "# tiktoken - OpenAI tokenizer library for their LLMs (GPT, Codex)\n",
    "import tiktoken\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers # The number of CPU processes to use for preprocessing\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jNfGcm7ck7ur",
   "metadata": {
    "id": "jNfGcm7ck7ur"
   },
   "source": [
    "## **Chapter 3: Multihead Attention Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hqqZKTdjfaUH",
   "metadata": {
    "id": "hqqZKTdjfaUH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout) # preventing overfitting - only used in training\n",
    "\n",
    "        # non-trainable parameters part of the model's state, move and save/load with the model\n",
    "        self.register_buffer(\"mask\", torch.triu(\n",
    "            torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # b - batches\n",
    "\n",
    "        queries = self.W_query(x) # b x d_in x d_in\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # creating HEADs: step 1\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # creating HEADs: step 2\n",
    "        queries = queries.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        att_scores = queries @ keys.transpose(2,3) # dot product\n",
    "\n",
    "\n",
    "        att_scores = att_scores.masked_fill(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens],\n",
    "            -torch.inf\n",
    "        )\n",
    "\n",
    "        # scale and normalize\n",
    "        att_weights = torch.softmax(\n",
    "            att_scores / keys.shape[-1] ** 0.5,\n",
    "            dim=-1\n",
    "            )\n",
    "\n",
    "        att_weights = self.dropout(att_weights)\n",
    "\n",
    "        context_vec = att_weights @ values # # (b, num_tokens, num_heads, head_dim)\n",
    "\n",
    "        # reverse shaping\n",
    "        context_vec = context_vec.transpose(1, 2) # (b, num_heads, num_tokens, head_dim)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rioOgPOpJbXk",
   "metadata": {
    "id": "rioOgPOpJbXk"
   },
   "source": [
    "- `torch.masked_fill(mask, par2)` - replaces elements in a tensor based on a mask. Mask has to be a tensor with values True and False, and of the same size as the tensor that is being masked. The second parameter is value put on positions with False value in the mask. In this case, `par2 = -torch.inf` because of the softmax function that will be applied to the masked tensor to normalize the values, and softmax treats negative infinity as 0, which is exactly what we want.\n",
    "\n",
    "- `torch.triu` - stands for upper triangular. It accepts the matrix, returns its upper triangle (everything on and above the diagonal), and sets everything below the diagonal to 0.\n",
    "\n",
    "        diagonal=0 (default) → keeps the main diagonal and everything above.\n",
    "\n",
    "        diagonal=1 → starts one above the main diagonal, excludes the main diagonal itself.\n",
    "\n",
    "        diagonal=2 → starts two rows above the main diagonal, and so on.\n",
    "\n",
    "- ***Scaling*** - solves the problem: \"...for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients\" Att. is all you need\n",
    "\n",
    "- `nn.Module.register_buffer('name', some_tensor)` - stores tensor as a parameter of the model class that is not learnable. It moves with the model when `.to(device)`, `.cuda()` or `.eval()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42Ovu0GFlZRq",
   "metadata": {
    "id": "42Ovu0GFlZRq"
   },
   "source": [
    "## **Chapter 4: GPT model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qCcpAe2VoKfA",
   "metadata": {
    "id": "qCcpAe2VoKfA"
   },
   "source": [
    "Classes:\n",
    "1. `LayerNorm`\n",
    "2. `FeedForward`\n",
    "3. `GELU`\n",
    "4. `TransformerBlock`\n",
    "5. `GPTmodel`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E5Dug9Etl33E",
   "metadata": {
    "id": "E5Dug9Etl33E"
   },
   "source": [
    "#### **GPT-2 configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "K0p1uqxjl92r",
   "metadata": {
    "id": "K0p1uqxjl92r"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768, # Embedding dimension\n",
    "    \"n_heads\": 12, # Number of attention heads\n",
    "    \"n_layers\": 12, # Number of layers\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Bhrsd8mjCMx",
   "metadata": {
    "id": "3Bhrsd8mjCMx"
   },
   "source": [
    "#### **1. Layer normalization**\n",
    "\n",
    "- normalization is introduced to address the problem of vanishing or exploding gradients that prevents model from efficient learning and adjusting weights. Normalization is done by adjusting transformer layers' outputs to have mean=0 and variance=1.\n",
    "- layer normalization normalizes across the feature dimension\n",
    "- scale and shift are aditional learnable parameters that are introduced to help model adjust itsels to data that is processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "q4HHHZYbLaHz",
   "metadata": {
    "id": "q4HHHZYbLaHz"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # helps avoid division by 0\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim)) # learnable\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) # learnable\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W0OySMJijxKw",
   "metadata": {
    "id": "W0OySMJijxKw"
   },
   "source": [
    "####**2. Feed firward network and 3. Activation function**\n",
    "- applies non-linear transformation to each token embedding individualy in order to capture more complex patterns in the data that linear transformations can not provide. If we used only linear transformations, the model — no matter how many layers deep — would collapse into a single linear function. That means it couldn’t learn complex things like syntax, semantic nuances, relationships, etc. By inserting non-linearities (like ReLU, GELU), we allow the model to bend and twist the data in useful ways. - *ChatGPT*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ZXeQb1kMWeg",
   "metadata": {
    "id": "1ZXeQb1kMWeg"
   },
   "source": [
    "**3. Activation function**\n",
    "\n",
    "Gaussian error linear unit\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smWywjd7RIt0",
   "metadata": {
    "id": "smWywjd7RIt0"
   },
   "outputs": [],
   "source": [
    "# activation function\n",
    "class GELU(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "                ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "NEmW681mkBDd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NEmW681mkBDd",
    "outputId": "fdec39f1-924e-490c-f5e7-53e3c7d747f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'reminder:This neural network can accommodate\\nvariable batch sizes and numbers of tokens in the input. However, the\\nembedding size for each token is determined and fixed when initializing\\nthe weights.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "'''reminder:This neural network can accommodate\n",
    "variable batch sizes and numbers of tokens in the input. However, the\n",
    "embedding size for each token is determined and fixed when initializing\n",
    "the weights.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-CIHYZ7DK6pT",
   "metadata": {
    "id": "-CIHYZ7DK6pT"
   },
   "source": [
    "#### **4. Transformer block**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y2PRj-VZLHwa",
   "metadata": {
    "id": "Y2PRj-VZLHwa"
   },
   "source": [
    "- this transformer block implements *Pre_Layer* normalization which leads to better training results than *Post-Layer* normalization (normalization after self-attention mechanism and feed-forwar layer) which was proposed in Attention is All You Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "P7zSayE3K5uQ",
   "metadata": {
    "id": "P7zSayE3K5uQ"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"], # dimension of input embeddings\n",
    "            d_out=cfg[\"emb_dim\"], # dimension of output embeddings\n",
    "            context_length=cfg[\"context_length\"], # number of tokens in one sequence\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"], # rate used for dropout\n",
    "            qkv_bias=cfg[\"qkv_bias\"]) # True/False - use bias in query, key and value weights matrices or not\n",
    "\n",
    "        self.ff = FeedForward(cfg)\n",
    "\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"]) # dropout layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multi-Head Self-Attention Layer\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # Feed-Forward Layer\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TSkR-lEggIIx",
   "metadata": {
    "id": "TSkR-lEggIIx"
   },
   "source": [
    "#### **5. GPT MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "-d0TzbEukBah",
   "metadata": {
    "id": "-d0TzbEukBah"
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "            )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "            )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        x = self.trf_blocks(x)\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "GuBdLYWIE28V",
   "metadata": {
    "id": "GuBdLYWIE28V"
   },
   "outputs": [],
   "source": [
    "# text generating function\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probabilities, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DP1eO_suFn_m",
   "metadata": {
    "id": "DP1eO_suFn_m"
   },
   "source": [
    "- `max_new_tokens` - user defined number of tokens that should be generated by the model\n",
    "- `idx` - (batch, number_of_tokens) array of token indices in the current context\n",
    "- `argmax` returns an index of the biggest number in the tensor\n",
    "- `cat` concatinates the tensors from the tuple on specified dimesion dim=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# **Chapter 5: Pretraining on Unlabeled Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92b989e9-da36-4159-b212-799184764dd9",
    "outputId": "3a03e908-cc37-49fd-e908-dce1a5a7e929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 2.0.2\n",
      "torch version: 2.6.0+cu124\n",
      "tiktoken version: 0.9.0\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"torch\",\n",
    "        \"tiktoken\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {
    "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237"
   },
   "source": [
    "- In this chapter, we implement the training loop and code for basic model evaluation to pretrain an LLM\n",
    "- At the end of this chapter, we also load openly available pretrained weights from OpenAI into our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {
    "id": "efd27fcc-2886-47cb-b544-046c2c31f02a"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\" width=900px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {
    "id": "0d214765-7a73-42d5-95e9-302154b29db9"
   },
   "source": [
    "- The topics covered in this chapter are shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {
    "id": "f67711d4-8391-4fee-aeef-07ea53dd5841"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 Evaluating generative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {
    "id": "a3350f8c-5181-4f9b-a789-4523105e98f2"
   },
   "source": [
    "- We start this section with a brief recap of initializing a GPT model using the code from the previous chapter\n",
    "- Then, we discuss basic evaluation metrics for LLMs\n",
    "- Lastly, in this section, we apply these evaluation metrics to a training and validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {
    "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc"
   },
   "source": [
    "- We initialize a GPT model using the code from the previous chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "id": "86000d74-624a-48f0-86da-f41926cb9e04"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {
    "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c"
   },
   "source": [
    "- We use dropout of 0.1 above, but it's relatively common to train LLMs without dropout nowadays\n",
    "- Modern LLMs also don't use bias vectors in the `nn.Linear` layers for the query, key, and value matrices (unlike earlier GPT models), which is achieved by setting `\"qkv_bias\": False`\n",
    "- We reduce the context length (`context_length`) of only 256 tokens to reduce the computational resource requirements for training the model, whereas the original 124 million parameter GPT-2 model used 1024 tokens\n",
    "  - This is so that more readers will be able to follow and execute the code examples on their laptop computer\n",
    "  - However, please feel free to increase the `context_length` to 1024 tokens (this would not require any code changes)\n",
    "  - We will also load a model with a 1024 `context_length` later from pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {
    "id": "59f80895-be35-4bb5-81cb-f357ef7367fe"
   },
   "source": [
    "- Next, we use the `generate_text_simple` function from the previous chapter to generate text\n",
    "- In addition, we define two convenience functions, `text_to_token_ids` and `token_ids_to_text`, for converting between token and text representations that we use throughout this chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {
    "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=1300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
    "outputId": "d6ac7416-1a05-4c31-ff2a-74db653cd9d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # adds the batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # removes the batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {
    "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305"
   },
   "source": [
    "- As we can see above, the model does not produce good text because it has not been trained yet\n",
    "- How do we measure or capture what \"good text\" is, in a numeric form, to track it during training?\n",
    "- The next subsection introduces metrics to calculate a loss metric for the generated outputs that we can use to measure the training progress\n",
    "- The next chapters on finetuning LLMs will also introduce additional ways to measure model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e",
   "metadata": {
    "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {
    "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440"
   },
   "source": [
    "- Suppose we have an `inputs` tensor containing the token IDs for 2 training examples (rows)\n",
    "- Corresponding to the `inputs`, the `targets` contain the desired token IDs that we want the model to generate\n",
    "- Notice that the `targets` are the `inputs` shifted by 1 position, as explained in chapter 2 when we implemented the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {
    "id": "33dc0645-ac2c-4973-9b40-6da40515bede"
   },
   "source": [
    "- Feeding the `inputs` to the model, we obtain the logits vector for the 2 input examples that consist of 3 tokens each\n",
    "- Each of the tokens is a 50,257-dimensional vector corresponding to the size of the vocabulary\n",
    "- Applying the softmax function, we can turn the logits tensor into a tensor of the same dimension containing probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
    "outputId": "f3a852c5-ac21-4c36-d25d-d43b4dda779d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability for each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {
    "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b"
   },
   "source": [
    "- The figure below, using a very small vocabulary for illustration purposes, outlines how we convert the probability scores back into text, which we discussed at the end of the previous chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {
    "id": "384d86a9-0013-476c-bb6b-274fd5f20b29"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {
    "id": "e8480efd-d419-4954-9ecc-2876055334bd"
   },
   "source": [
    "- As discussed in the previous chapter, we can apply the `argmax` function to convert the probability scores into predicted token IDs\n",
    "- The softmax function above produced a 50,257-dimensional vector for each token; the `argmax` function returns the position of the highest probability score in this vector, which is the predicted token ID for the given token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {
    "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144"
   },
   "source": [
    "- Since we have 2 input batches with 3 tokens each, we obtain 2 by 3 predicted token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "be4d8dd4-735b-4eda-843e-2fb162fd21f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True) # model's prediction\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {
    "id": "cee4072c-21ed-4df7-8721-dd2535362573"
   },
   "source": [
    "- If we decode these tokens, we find that these are quite different from the tokens we want the model to predict, namely the target tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
    "outputId": "51ba0d67-a2b4-471d-c682-bbf2c5e56c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {
    "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2"
   },
   "source": [
    "- That's because the model wasn't trained yet\n",
    "- To train the model, we need to know how far it is away from the correct predictions (targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {
    "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=1100px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {
    "id": "c7251bf5-a079-4782-901d-68c9225d3157"
   },
   "source": [
    "- The token probabilities corresponding to the target indices are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "7ad6a126-ca79-495a-c958-4741a9010b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] # [3626, 6100, 345], # [\" effort moves you\",\n",
    "print(probas.shape)\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]] # [1107,  588, 11311] \" really like chocolate\"]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {
    "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf"
   },
   "source": [
    "- *The goal of training the LLM is to maximize the likelihood of the correct (target) token by increasing its probability relative to other tokens ->* We want to maximize all these values, bringing them close to a probability of 1.\n",
    "\n",
    "    *HOW? -> by **backpropagation**, updating the model's trainable parameters so that model outputs higher values for the respective token IDs we want to generate. Backpropagation requires **a loss function**, which calculates the difference between the model’s predicted output (here, the probabilities corresponding to the target token IDs) and the actual desired output. This loss function measures how far off the model’s predictions are from the target values.*  \n",
    "\n",
    "\n",
    "- In mathematical optimization, it is easier to maximize the logarithm of the probability score than the probability score itself; this is out of the scope of this book, but the author has recorded a lecture with more details here: [L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {
    "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qptmXQmg3Xgj",
   "metadata": {
    "id": "qptmXQmg3Xgj"
   },
   "source": [
    "**Cross-entropy** definition from the book:\n",
    "\n",
    "\n",
    "> At its core, the cross entropy loss is a popular measure in machine learning and deep\n",
    "learning that measures the difference between two probability distributions—typically,\n",
    "the true distribution of labels (here, tokens in a dataset) and the predicted distribution\n",
    "from a model (for instance, the token probabilities generated by an LLM).\n",
    "\n",
    "\n",
    "\n",
    "Formula for cross-enthropy ([Cross-enthropy wiki](https://en.wikipedia.org/wiki/Cross-entropy))\n",
    "\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/f96687b6197ab61a2d07a82410e640f3a32c8403\" width=300px>\n",
    "\n",
    "- **p** is a true distribution of tokens in the vocabulary\n",
    "- **q** is a distribution of tokens in the vocabulary predicted by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gEAmX1y4KpGu",
   "metadata": {
    "id": "gEAmX1y4KpGu"
   },
   "source": [
    "Formula for cross-enthropy estimation in cases when true distribution is unknown, used in language modeling ([Cross-entropy estimation wiki](https://en.wikipedia.org/wiki/Cross-entropy#Estimation))\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/bb11eae1b2b1120c2bcccf741a51c2511c0cbffe\" width=300px>\n",
    "\n",
    "- **N** is the size of the test set (number of tokens in a sequence/batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "0030974a-106b-4002-b097-5b244dcdc9f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {
    "id": "c4261441-a511-4633-9c4c-67998af31b84"
   },
   "source": [
    "- Next, we compute the average log probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "00078bcd-1746-46fd-8c25-743deffabb33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {
    "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514"
   },
   "source": [
    "- In deep learning, instead of maximizing the average log-probability, it's a standard convention to minimize the *negative* average log-probability value; in our case, instead of maximizing -10.7722 so that it approaches 0, in deep learning, we would minimize 10.7722 so that it approaches 0\n",
    "- The value negative of -10.7722, i.e., 10.7722, is also called **cross-entropy loss** in deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
    "outputId": "30c32be5-c4ce-48d2-e7e5-422e95fc69e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {
    "id": "84eeb868-abd8-4028-82db-107546bf7c2c"
   },
   "source": [
    "- PyTorch already implements a `cross_entropy` function that carries out the previous steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {
    "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d"
   },
   "source": [
    "- Before we apply the `cross_entropy` function, let's check the shape of the logits and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "169696ef-3e82-4b81-9278-25507d140a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {
    "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06"
   },
   "source": [
    "- For the `cross_entropy` function in PyTorch, we want to flatten these tensors by combining them over the batch dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "c40eb31b-622a-4491-d55e-8d6732277940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {
    "id": "4921a57f-3a79-473e-a863-6d63b495010f"
   },
   "source": [
    "- Note that the targets are the token IDs, which also represent the index positions in the logits tensors that we want to maximize\n",
    "- The `cross_entropy` function in PyTorch will automatically take care of applying the softmax and log-probability computation internally over those token indices in the logits that are to be maximized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "381fb11e-4806-4fd5-dc07-6b937af862d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {
    "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80"
   },
   "source": [
    "**Perplexity**\n",
    "- A concept related to the cross-entropy loss is the perplexity of an LLM\n",
    "\n",
    "\n",
    "> In information theory, perplexity is a measure of uncertainty in the value of a sample from a discrete probability distribution. The larger the perplexity, the less likely it is that an observer can guess the value which will be drawn from the distribution. [wiki](https://en.wikipedia.org/wiki/Perplexity)\n",
    "\n",
    "\n",
    "- The perplexity is simply the exponential of the cross-entropy loss and can be calculated as `perplexity = torch.exp(loss)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W4k6xtirljkF",
   "metadata": {
    "id": "W4k6xtirljkF"
   },
   "source": [
    "*notes from https://machinelearningmastery.com/cross-entropy-for-machine-learning/*\n",
    "\n",
    "The intuition behind quantifying information is the idea of measuring how much surprise there is in an event. Those events that are rare (low probability) are more surprising and therefore have more information than those events that are common (high probability).\n",
    "\n",
    "- Low Probability Event: High Information (surprising).\n",
    "- High Probability Event: Low Information (unsurprising).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "e0ff05e4-3cb8-4b7d-e1ad-059d480e9f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {
    "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7"
   },
   "source": [
    "- The perplexity is often considered more interpretable because it can be understood as the effective vocabulary size that the model is uncertain about at each step (in the example above, that'd be 48,725 words or tokens)\n",
    "- In other words, perplexity provides a measure of how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset\n",
    "- Similar to the loss, a lower perplexity indicates that the model predictions are closer to the actual distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {
    "id": "530da89e-2448-436c-8f1b-28e8a31ef85c"
   },
   "source": [
    "- We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
    "- The reasons are:\n",
    "  - You can run the code examples in a few minutes on a laptop computer without a suitable GPU\n",
    "  - The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes\n",
    "  - We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights or bloating the repository size\n",
    "\n",
    "\n",
    "- For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n",
    "  - At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately \\\\$30\n",
    "  - So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * \\\\$30 =  \\\\$690,000\n",
    "\n",
    "- Below, we use the same dataset we used in chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {
    "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {
    "id": "379330f1-80f4-4e34-8724-41d892b04cee"
   },
   "source": [
    "- A quick check that the text loaded ok by printing the first and last 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "43366fbc-9e85-43b6-d075-656dd8bee663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2XPde_ThM_e",
    "outputId": "4f537349-1700-4438-9bff-5b56016bfbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "c1ae1c82-9cce-4b0b-f0d7-12e2fcf42746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {
    "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7"
   },
   "source": [
    "- With 5,145 tokens, the text is very short for training an LLM, but again, it's for educational purposes (we will also load pretrained weights later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {
    "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f"
   },
   "source": [
    "- Next, we divide the dataset into a training and a validation set and use the data loaders from chapter 2 to prepare the batches for LLM training\n",
    "- For visualization purposes, the figure below assumes a `max_length=6`, but for the training loader, we set the `max_length` equal to the context length that the LLM supports\n",
    "- The figure below only shows the input tokens for simplicity\n",
    "    - Since we train the LLM to predict the next word in the text, the targets look the same as these inputs, except that the targets are shifted by one position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {
    "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {
    "id": "0959c855-f860-4358-8b98-bc654f047578"
   },
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {
    "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e"
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {
    "id": "e7ac3296-a4d1-4303-9ac5-376518960c33"
   },
   "source": [
    "- We use a relatively small batch size to reduce the computational resource demand, and because the dataset is very small to begin with\n",
    "- Llama 2 7B was trained with a batch size of 1024, for example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {
    "id": "a8e0514d-b990-4dc0-9afb-7721993284a0"
   },
   "source": [
    "- An optional check that the data was loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
    "outputId": "0a7215a5-c267-4def-fe2b-35bae2e9e3f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {
    "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed"
   },
   "source": [
    "- Another optional check that the token sizes are in the expected ballpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "2ba19487-d911-4885-c5c1-acb31d52f525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {
    "id": "5c3085e8-665e-48eb-bb41-cdde61537e06"
   },
   "source": [
    "- Next, we implement a utility function to calculate the cross-entropy loss of a given batch\n",
    "- In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch) # model = model.to(device) ?\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {
    "id": "f0691332-84d0-48b3-b462-a885ddeb4fca"
   },
   "source": [
    "- If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code\n",
    "- Via the `device` setting, we ensure that the data is loaded onto the same device as the LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
    "outputId": "ea8b0949-17c4-4313-db76-8e93c8da4567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583266364204\n",
      "Validation loss: 10.981104850769043\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {
    "id": "43875e95-190f-4b17-8f9a-35034ba649ec"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {
    "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd"
   },
   "source": [
    "- In this section, we finally implement the code for training the LLM\n",
    "- We focus on a simple training function (if you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to [Appendix D](../../appendix-D/01_main-chapter-code))\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=700px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {
    "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47"
   },
   "source": [
    "- Now, let's train the LLM using the training function defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "8289b97e-2522-4b3f-e221-aebe16807051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.930\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.336\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.623, Val loss 7.053\n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.605\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.532, Val loss 6.507\n",
      "Ep 3 (Step 000025): Train loss 5.399, Val loss 6.389\n",
      "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 4.895, Val loss 6.280\n",
      "Ep 4 (Step 000035): Train loss 4.648, Val loss 6.304\n",
      "Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 4.023, Val loss 6.165\n",
      "Every effort moves you know                                                 \n",
      "Ep 6 (Step 000045): Train loss 3.625, Val loss 6.172\n",
      "Ep 6 (Step 000050): Train loss 3.045, Val loss 6.144\n",
      "Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n",
      "Ep 7 (Step 000055): Train loss 2.948, Val loss 6.183\n",
      "Ep 7 (Step 000060): Train loss 2.230, Val loss 6.128\n",
      "Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.774, Val loss 6.162\n",
      "Ep 8 (Step 000070): Train loss 1.475, Val loss 6.229\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.135, Val loss 6.268\n",
      "Ep 9 (Step 000080): Train loss 0.858, Val loss 6.298\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
      "Ep 10 (Step 000085): Train loss 0.627, Val loss 6.382\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Training completed in 0.59 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204",
   "metadata": {
    "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204"
   },
   "source": [
    "- Note that you might get slightly different loss values on your computer, which is not a reason for concern if they are roughly similar (a training loss below 1 and a validation loss below 7)\n",
    "- Small differences can often be due to different GPU hardware and CUDA versions or small changes in newer PyTorch versions\n",
    "- Even if you are running the example on a CPU, you may observe slight differences; a possible reason for a discrepancy is the differing behavior of `nn.Dropout` across operating systems, depending on how PyTorch was compiled, as discussed [here on the PyTorch issue tracker](https://github.com/pytorch/pytorch/issues/121595)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "28c4ebfe-27c5-4a19-8e62-8c61db09a743"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {
    "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995"
   },
   "source": [
    "- Looking at the results above, we can see that the model starts out generating incomprehensible strings of words, whereas towards the end, it's able to produce grammatically more or less correct sentences\n",
    "- However, based on the training and validation set losses, we can see that the model starts overfitting\n",
    "- If we were to check a few passages it writes towards the end, we would find that they are contained in the training set verbatim -- it simply memorizes the training data\n",
    "- Later, we will cover decoding strategies that can mitigate this memorization by a certain degree\n",
    "- Note that the overfitting here occurs because we have a very, very small training set, and we iterate over it so many times\n",
    "  - The LLM training here primarily serves educational purposes; we mainly want to see that the model can learn to produce coherent text\n",
    "  - Instead of spending weeks or months on training this model on vast amounts of expensive hardware, we load pretrained weights later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {
    "id": "eb380c42-b31c-4ee1-b8b9-244094537272"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=750px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de713235-1561-467f-bf63-bf11ade383f0",
   "metadata": {
    "id": "de713235-1561-467f-bf63-bf11ade383f0"
   },
   "source": [
    "**If you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to [Appendix D](../../appendix-D/01_main-chapter-code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {
    "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c"
   },
   "source": [
    "## ...\n",
    " **If you are interested in a larger training dataset and longer training run, see [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ljD_6KlDv4j9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ljD_6KlDv4j9",
    "outputId": "d69507dd-6f36-4d86-e66d-69a5a41e0c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "etH2yHgF01ij",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "746a6d27fe6044b68a64aefbc305ebb8",
      "e2eb1320a0d1404f851f8483a4d288d3",
      "2596b1e2f44d4e48a6ac0713925927af",
      "5a9ed58be584483ab586febe2e14144a",
      "fbf9d203376f49b29c9b54ca44f7a33b",
      "51a4591f715a492b8fb33f0fe06ed758",
      "f05f787eff774df0a0a656c737fb8f98",
      "45448ce5b9d64bccbfc15fba04227b41",
      "acd80fbfab1d4600b317b6e313651591",
      "fe385d377c2a44ea9e4f3ef99d80c231",
      "1ba6ac560ec6457d82f054fc3b0079b8"
     ]
    },
    "collapsed": true,
    "id": "etH2yHgF01ij",
    "outputId": "25cbd293-b680-4d87-94a2-2123bf74b24d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746a6d27fe6044b68a64aefbc305ebb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds_gutenberg = load_dataset(\"manu/project_gutenberg\", split=\"en\", streaming=True)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "hrrxoLfY01x3",
   "metadata": {
    "id": "hrrxoLfY01x3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from itertools import islice, tee\n",
    "\n",
    "# Dataset class\n",
    "class HFStreamingDataset(IterableDataset):\n",
    "    def __init__(self, hf_iterable_dataset, tokenizer, max_length=512):\n",
    "        self.dataset = hf_iterable_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.context_size = max_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        for book in self.dataset:\n",
    "            text = book[\"text\"]\n",
    "            token_ids = self.tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "            for i in range(0, len(token_ids) - self.context_size, self.context_size):\n",
    "                input_chunk = token_ids[i:i + self.context_size]\n",
    "                target_chunk = token_ids[i + 1:i + self.context_size + 1]\n",
    "                yield torch.tensor(input_chunk), torch.tensor(target_chunk)\n",
    "\n",
    "\n",
    "# Utility function to create train/val data loaders\n",
    "def create_streaming_loaders(hf_streaming_dataset, tokenizer, context_size=512,\n",
    "                              num_books=10, val_books=1, batch_size=4):\n",
    "    assert val_books < num_books\n",
    "\n",
    "    # Split the dataset stream using tee and islice\n",
    "    stream1, stream2 = tee(hf_streaming_dataset) # use tee to duplicate the iterable\n",
    "    stream1 = islice(stream1, 0, num_books - val_books) # extract train books\n",
    "    stream2 = islice(stream2, num_books - val_books, num_books) # extract validation books, corrected slicing\n",
    "\n",
    "    training_dataset = HFStreamingDataset(stream1, tokenizer, context_size)\n",
    "    validation_dataset = HFStreamingDataset(stream2, tokenizer, context_size)\n",
    "\n",
    "    training_loader = DataLoader(training_dataset, batch_size=batch_size)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "\n",
    "    return training_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "NDBokR8U0116",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDBokR8U0116",
    "outputId": "1e905107-14c4-4dfa-d7ac-f0f91c4c80b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  464,  4935, 20336,  ...,   262,  8009,   326],\n",
      "        [  262,  2426,    12,  ...,  2911,   326,   314],\n",
      "        [ 2236,   307,   517,  ...,   379,   262,   198],\n",
      "        [   62,    35,  6570,  ..., 29167,   438,   265]])\n",
      "tensor([[ 4935, 20336,   412,  ...,  8009,   326,   262],\n",
      "        [ 2426,    12, 47635,  ...,   326,   314,  2236],\n",
      "        [  307,   517,  4388,  ...,   262,   198,    62],\n",
      "        [   35,  6570,   710,  ...,   438,   265,   198]])\n",
      "tensor([[  198,  4758,  2278,  ...,    67,   735,  9413],\n",
      "        [17435,   438, 40965,  ..., 13795,   395,  1393],\n",
      "        [  262,  3715,   286,  ...,   750,   616,   898],\n",
      "        [  198, 42946,  9278,  ...,    11,   290,   198]])\n",
      "tensor([[ 4758,  2278,   428,  ...,   735,  9413, 17435],\n",
      "        [  438, 40965,   890,  ...,   395,  1393,   262],\n",
      "        [ 3715,   286,   198,  ...,   616,   898,   198],\n",
      "        [42946,  9278,    11,  ...,   290,   198,   400]])\n"
     ]
    }
   ],
   "source": [
    "training_loader, validation_loader = create_streaming_loaders(ds_gutenberg, tokenizer)\n",
    "\n",
    "for i, (input_loader, target_loader) in enumerate(validation_loader):\n",
    "    print(input_loader[:10])\n",
    "    print(target_loader[:10])\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {
    "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7"
   },
   "source": [
    "- Inference is relatively cheap with a relatively small LLM as the GPT model we trained above, so there's no need to use a GPU for it in case you used a GPU for training it above\n",
    "- Using the `generate_text_simple` function (from the previous chapter) that we used earlier inside the simple training function, we can generate new text one word (or token) at a time\n",
    "- As explained in section 5.1.2, the next generated token is the token corresponding to the largest probability score among all tokens in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
    "outputId": "d7c4261d-2800-4509-cf05-5f4e1d5bd405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {
    "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4"
   },
   "source": [
    "- Even if we execute the `generate_text_simple` function above multiple times, the LLM will always generate the same outputs\n",
    "- We now introduce two concepts, so-called decoding strategies, to modify the `generate_text_simple`: *temperature scaling* and *top-k* sampling\n",
    "- These will allow the model to control the randomness and diversity of the generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {
    "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994"
   },
   "source": [
    "### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {
    "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa"
   },
   "source": [
    "- Previously, we always sampled the token with the highest probability as the next token using `torch.argmax`\n",
    "- To add variety, we can sample the next token using The `torch.multinomial(probs, num_samples=1)`, sampling from a probability distribution\n",
    "- Here, each index's chance of being picked corresponds to its probability in the input tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {
    "id": "e7531bae-d5de-44c0-bc78-78fed077e22a"
   },
   "source": [
    "- Here's a little recap of generating the next token, assuming a very small vocabulary for illustration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
    "outputId": "bc67360a-ee7f-4e08-920a-5e9a6e6490fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
    "outputId": "e4dfdbf6-a14b-419f-d14c-7fa39b5d643d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {
    "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9"
   },
   "source": [
    "- Instead of determining the most likely token via `torch.argmax`, we use `torch.multinomial(probas, num_samples=1)` to determine the most likely token by sampling from the softmax distribution\n",
    "\n",
    "\n",
    "    \n",
    "    General idea behind multinominal sampling:\n",
    "        1. compute the cumulative distribution function (CDF) for each token position;\n",
    "        2. generate a random number N from a uniform distribution [0, 1);\n",
    "        3. Find the first index i where `CDF[i] > N`\n",
    "    \n",
    "- For illustration purposes, let's see what happens when we sample the next token 1,000 times using the original softmax probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
    "outputId": "fabafba3-f59e-4708-80d1-940644abfb15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {
    "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832"
   },
   "source": [
    "- We can control the distribution and selection process via a concept called temperature scaling\n",
    "- \"Temperature scaling\" is just a fancy word for dividing the logits by a number greater than 0\n",
    "- Temperatures greater than 1 will result in more uniformly distributed token probabilities after applying the softmax\n",
    "- Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions after applying the softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {
    "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d"
   },
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
    "outputId": "08395df2-62d1-42f5-9ac1-2cb5d25ac1bf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWghJREFUeJzt3XtclGX+//H3gHKSk4aCBxJMS03EU7pYnsrytKa5mZmmkvpbyyMsWpaC4iqulZnfLMtTWpq2ptZmWUbiKU3NY+VhURHWAC0TwgMgzO8P19lGkIAbvAd9PR+PecRcc90zH+7G4X7PfV33ZbFarVYBAAAAgAFOZhcAAAAAoOIjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMqmV3AzZafn6+ffvpJXl5eslgsZpcDAAAAOCyr1arffvtNtWrVkpNT0eckbrtg8dNPPykwMNDsMgAAAIAKIyUlRXXq1Cmyz20XLLy8vCRd3Tne3t4mVwMAAAA4rszMTAUGBtqOoYty2wWLa8OfvL29CRYAAABAMRRnCgGTtwEAAAAYRrAAAAAAYBjBAgAAAIBht90cCwAAgLKSn5+vnJwcs8sASq1y5cpydnYuk+ciWAAAAJRCTk6OTp48qfz8fLNLAQzx9fVVQECA4TXeCBYAAAAlZLValZqaKmdnZwUGBv7hwmGAI7Jarbp48aLOnDkjSapZs6ah5yNYAAAAlNCVK1d08eJF1apVSx4eHmaXA5Sau7u7JOnMmTOqUaOGoWFRxGsAAIASysvLkyS5uLiYXAlg3LVwnJuba+h5CBYAAAClZHRMOuAIyup9TLAAAAAAYBjBAgAA4DZgsViKvE2ZMsXsEstcUFCQ5syZY3YZhowZM0YtW7aUq6urmjVrZnY5RWLyNgAAQBkJemH9TX29pJk9it03NTXV9vOqVasUHR2to0eP2to8PT3LtLbyYrValZeXp0qVbt5hbE5OjqnzaZ555hl9++23OnjwoGk1FIepZyy2bNminj17qlatWrJYLFq3bt0fbpOQkKAWLVrI1dVV9evX17vvvlvudQIAAFR0AQEBtpuPj48sFotd28qVK9WoUSO5ubmpYcOGevPNN23bJiUlyWKx6MMPP1S7du3k7u6u++67T8eOHdPu3bvVqlUreXp6qlu3bjp79qxtuyFDhqh3796aOnWqqlevLm9vb40YMcJuUcH8/HzFxcUpODhY7u7uCg0N1erVq22PJyQkyGKx6PPPP7d9c79t2zYdP35cvXr1kr+/vzw9PXXffffpq6++sm3XsWNHnTp1ShEREbazMpI0ZcqUAt/8z5kzR0FBQQXqnj59umrVqqV77rlHkpSSkqInnnhCvr6+qlatmnr16qWkpKSy+N9zQ3PnztXIkSNVr169cn2dsmBqsLhw4YJCQ0M1b968YvU/efKkevTooU6dOmn//v0aN26chg0bpi+++KKcKwUAALh1LV++XNHR0Zo+fboOHz6sGTNmaPLkyVq6dKldv5iYGE2aNEl79+5VpUqV9NRTT2nChAl6/fXXtXXrViUmJio6Otpum/j4eB0+fFgJCQn64IMPtGbNGk2dOtX2eFxcnJYtW6b58+frhx9+UEREhAYOHKjNmzfbPc8LL7ygmTNn6vDhw2ratKmysrLUvXt3xcfHa9++feratat69uyp5ORkSdKaNWtUp04dxcbGKjU11e6MTXHEx8fr6NGj2rhxoz799FPl5uaqS5cu8vLy0tatW7V9+3Z5enqqa9euRa6+7unpWeRtxIgRJarLkZk6FKpbt27q1q1bsfvPnz9fwcHBevXVVyVJjRo10rZt2/Taa6+pS5cu5VUmAADALS0mJkavvvqq+vTpI0kKDg7Wjz/+qLfffluDBw+29YuKirIdc40dO1b9+/dXfHy87r//fknS0KFDC4wmcXFx0eLFi+Xh4aF7771XsbGxGj9+vKZNm6bc3FzNmDFDX331lcLCwiRJ9erV07Zt2/T222+rQ4cOtueJjY3Vww8/bLtfrVo1hYaG2u5PmzZNa9eu1SeffKJRo0apWrVqcnZ2lpeXlwICAkq8T6pUqaKFCxfahkC9//77ys/P18KFC21nP5YsWSJfX18lJCTokUceKfR59u/fX+TreHt7l7g2R1Wh5ljs2LFDnTt3tmvr0qWLxo0bZ05BAAAAFdyFCxd0/PhxDR06VMOHD7e1X7lyRT4+PnZ9mzZtavvZ399fkhQSEmLXdm0V52tCQ0PtFhEMCwtTVlaWUlJSlJWVpYsXL9oFBunqnIbmzZvbtbVq1cruflZWlqZMmaL169crNTVVV65c0aVLl2xnLIwKCQmxm1dx4MABJSYmysvLy67f5cuXdfz48Rs+T/369cuknoqgQgWLtLQ025v4Gn9/f2VmZurSpUu2lQN/Lzs7W9nZ2bb7mZmZ5V4nAABARZGVlSVJWrBggdq0aWP32PWrMFeuXNn287Vv7a9vy8/PL/Frr1+/XrVr17Z7zNXV1e5+lSpV7O5HRUVp48aNeuWVV1S/fn25u7vr8ccfL3JYkiQ5OTnJarXatRW2MNz1r5eVlaWWLVtq+fLlBfpWr179hq/3R5PiBw4cqPnz5xfZp6KoUMGiNOLi4uzG8QEAAOB//P39VatWLZ04cUIDBgwo8+c/cOCA3RfAO3fulKenpwIDA1WtWjW5uroqOTnZbthTcWzfvl1DhgzRY489Junqgf/1E6ldXFxsq6RfU716daWlpclqtdrC0R8NV5KkFi1aaNWqVapRo0aJhi8xFMpBBQQEKD093a4tPT1d3t7ehZ6tkKSJEycqMjLSdj8zM1OBgYHlWicAAEBFMnXqVI0ZM0Y+Pj7q2rWrsrOztWfPHv366692x1GlkZOTo6FDh2rSpElKSkpSTEyMRo0aJScnJ3l5eSkqKkoRERHKz8/XAw88oIyMDG3fvl3e3t528zuu16BBA61Zs0Y9e/aUxWLR5MmTC5wtCQoK0pYtW/Tkk0/K1dVVfn5+6tixo86ePatZs2bp8ccf14YNG/T555//4QH+gAED9PLLL6tXr16KjY1VnTp1dOrUKa1Zs0YTJkxQnTp1Ct3O6FCoxMREZWVlKS0tTZcuXbIFlcaNG5t6CdzCVKhgERYWps8++8yubePGjbbJPoVxdXUtcCoNAAAA/zNs2DB5eHjo5Zdf1vjx41WlShWFhISUyTzWhx56SA0aNFD79u2VnZ2t/v372y3GN23aNFWvXl1xcXE6ceKEfH191aJFC7344otFPu/s2bP1zDPPqG3btvLz89Pzzz9fYMh7bGys/vrXv+quu+5Sdna2rFarGjVqpDfffFMzZszQtGnT9Je//EVRUVF65513inw9Dw8PbdmyRc8//7z69Omj3377TbVr19ZDDz1Urmcdhg0bZneFrGtzT06ePGl3iVxHYLFeP8jsJsrKylJiYqKkqztp9uzZ6tSpk6pVq6Y777xTEydO1OnTp7Vs2TJJV3dgkyZNNHLkSD3zzDP6+uuvNWbMGK1fv77YV4XKzMyUj4+PMjIybqlTTwAA4Oa5fPmyTp48qeDgYLm5udnaHXmBPDMMGTJE58+fL9ZaZTDPjd7PUsmOnU09Y7Fnzx516tTJdv/aqbbBgwfr3XffVWpqqt3M/uDgYK1fv14RERF6/fXXVadOHS1cuJBLzQIw1xSfP+5j65tRfnUAMJ2jH+gD5cnUYNGxY8cCs/J/r7BVtTt27Kh9+/aVY1UAAAAASqpCzbEAAABAxVHYl8S4dTmZXQAAAACAio9gAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAC3AYvFUuRtypQpZpdY5oKCgjRnzhyzyzAkOTlZPXr0kIeHh2rUqKHx48frypUrRW4zffp0tW3bVh4eHvL19b05hYoF8gAAAMrOFJ+b/HoZxe6amppq+3nVqlWKjo7W0aNHbW2enp5lWlp5sVqtysvLU6VKN+8wNicnRy4uLjft9a7Jy8tTjx49FBAQoG+++UapqakaNGiQKleurBkzZtxwu5ycHPXt21dhYWFatGjRTauXMxYAAAC3gYCAANvNx8dHFovFrm3lypVq1KiR3Nzc1LBhQ7355pu2bZOSkmSxWPThhx+qXbt2cnd313333adjx45p9+7datWqlTw9PdWtWzedPXvWtt2QIUPUu3dvTZ06VdWrV5e3t7dGjBihnJwcW5/8/HzFxcUpODhY7u7uCg0N1erVq22PJyQkyGKx6PPPP1fLli3l6uqqbdu26fjx4+rVq5f8/f3l6emp++67T1999ZVtu44dO+rUqVOKiIiwnZWRpClTpqhZs2Z2+2bOnDkKCgoqUPf06dNVq1Yt3XPPPZKklJQUPfHEE/L19VW1atXUq1cvJSUllcX/nkJ9+eWX+vHHH/X++++rWbNm6tatm6ZNm6Z58+bZ7cPrTZ06VREREQoJCSm32gpDsAAAALjNLV++XNHR0Zo+fboOHz6sGTNmaPLkyVq6dKldv5iYGE2aNEl79+5VpUqV9NRTT2nChAl6/fXXtXXrViUmJio6Otpum/j4eB0+fFgJCQn64IMPtGbNGk2dOtX2eFxcnJYtW6b58+frhx9+UEREhAYOHKjNmzfbPc8LL7ygmTNn6vDhw2ratKmysrLUvXt3xcfHa9++feratat69uyp5ORkSdKaNWtUp04dxcbGKjU11e6MTXHEx8fr6NGj2rhxoz799FPl5uaqS5cu8vLy0tatW7V9+3Z5enqqa9euRR7ke3p6FnkbMWLEDbfdsWOHQkJC5O/vb2vr0qWLMjMz9cMPP5To97kZGAoFAABwm4uJidGrr76qPn36SJKCg4P1448/6u2339bgwYNt/aKiotSlSxdJ0tixY9W/f3/Fx8fr/vvvlyQNHTpU7777rt1zu7i4aPHixfLw8NC9996r2NhYjR8/XtOmTVNubq5mzJihr776SmFhYZKkevXqadu2bXr77bfVoUMH2/PExsbq4Ycftt2vVq2aQkNDbfenTZumtWvX6pNPPtGoUaNUrVo1OTs7y8vLSwEBASXeJ1WqVNHChQttQ6Def/995efna+HChbazH0uWLJGvr68SEhL0yCOPFPo8+/fvL/J1vL29b/hYWlqaXaiQZLuflpZW3F/lpiFYAAAA3MYuXLig48ePa+jQoRo+fLit/cqVK/LxsZ8z0rRpU9vP1w5wfz/cxt/fX2fOnLHbJjQ0VB4eHrb7YWFhysrKUkpKirKysnTx4kW7wCBdnSPQvHlzu7ZWrVrZ3c/KytKUKVO0fv16paam6sqVK7p06ZLtjIVRISEhdvMqDhw4oMTERHl5edn1u3z5so4fP37D56lfv36Z1FMRECwAAABuY1lZWZKkBQsWqE2bNnaPOTs7292vXLmy7edr39pf35afn1/i116/fr1q165t95irq6vd/SpVqtjdj4qK0saNG/XKK6+ofv36cnd31+OPP17ksCRJcnJyktVqtWvLzc0t0O/618vKylLLli21fPnyAn2rV69+w9f7o0nxAwcO1Pz58wt9LCAgQLt27bJrS09Ptz3maAgWAAAAtzF/f3/VqlVLJ06c0IABA8r8+Q8cOKBLly7J3d1dkrRz5055enoqMDBQ1apVk6urq5KTk+2GPRXH9u3bNWTIED322GOSrh74Xz+R2sXFRXl5eXZt1atXV1pamqxWqy0c/dFwJUlq0aKFVq1apRo1ahQ5fOl6RoZChYWFafr06Tpz5oxq1KghSdq4caO8vb3VuHHjYtdwsxAsAAAAbnNTp07VmDFj5OPjo65duyo7O1t79uzRr7/+qsjISEPPnZOTo6FDh2rSpElKSkpSTEyMRo0aJScnJ3l5eSkqKkoRERHKz8/XAw88oIyMDG3fvl3e3t528zuu16BBA61Zs0Y9e/aUxWLR5MmTC5wtCQoK0pYtW/Tkk0/K1dVVfn5+6tixo86ePatZs2bp8ccf14YNG/T555//YVgYMGCAXn75ZfXq1UuxsbGqU6eOTp06pTVr1mjChAmqU6dOodsZGQr1yCOPqHHjxnr66ac1a9YspaWladKkSRo5cqTtjM6uXbs0aNAgxcfH2876JCcn69y5c0pOTlZeXp4t3NSvX79cLyvMVaEAAABuc8OGDdPChQu1ZMkShYSEqEOHDnr33XcVHBxs+LkfeughNWjQQO3bt1e/fv306KOP2i3GN23aNE2ePFlxcXFq1KiRunbtqvXr1//ha8+ePVtVq1ZV27Zt1bNnT3Xp0kUtWrSw6xMbG6ukpCTdddddtuFKjRo10ptvvql58+YpNDRUu3btUlRU1B/+Hh4eHtqyZYvuvPNO9enTR40aNdLQoUN1+fLlEp3BKAlnZ2d9+umncnZ2VlhYmAYOHKhBgwYpNjbW1ufixYs6evSo3XCu6OhoNW/eXDExMcrKylLz5s3VvHlz7dmzp1zqvMZivX6Q2S0uMzNTPj4+ysjIKLc3AYDbTEkWxCrBYlYAHNfly5d18uRJBQcHy83NzexyHNaQIUN0/vx5rVu3zuxSUISi3s8lOXbmjAUAAAAAwwgWAAAAAAxj8jYAAADKxfWL5eHWxhkLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAADgNmCxWIq8TZkyxewSy1xQUJDmzJljdhmGFPb/auXKlWaXVSgWyAMAACgjIUtDburrHRp8qNh9U1NTbT+vWrVK0dHROnr0qK3N09OzTGsrL1arVXl5eapU6eYdxubk5MjFxeWmvd71lixZoq5du9ru+/r6mlZLUThjAQAAcBsICAiw3Xx8fGSxWOzaVq5cqUaNGsnNzU0NGzbUm2++ads2KSlJFotFH374odq1ayd3d3fdd999OnbsmHbv3q1WrVrJ09NT3bp109mzZ23bDRkyRL1799bUqVNVvXp1eXt7a8SIEcrJybH1yc/PV1xcnIKDg+Xu7q7Q0FCtXr3a9nhCQoIsFos+//xztWzZUq6urtq2bZuOHz+uXr16yd/fX56enrrvvvv01Vdf2bbr2LGjTp06pYiICNs3/ZI0ZcoUNWvWzG7fzJkzR0FBQQXqnj59umrVqqV77rlHkpSSkqInnnhCvr6+qlatmnr16qWkpKSy+N9TJF9fX7v/V25ubuX+mqVBsAAAALjNLV++XNHR0Zo+fboOHz6sGTNmaPLkyVq6dKldv5iYGE2aNEl79+5VpUqV9NRTT2nChAl6/fXXtXXrViUmJio6Otpum/j4eB0+fFgJCQn64IMPtGbNGk2dOtX2eFxcnJYtW6b58+frhx9+UEREhAYOHKjNmzfbPc8LL7ygmTNn6vDhw2ratKmysrLUvXt3xcfHa9++feratat69uyp5ORkSdKaNWtUp04dxcbGKjU11e6MTXHEx8fr6NGj2rhxoz799FPl5uaqS5cu8vLy0tatW7V9+3Z5enqqa9eudkHpep6enkXeRowY8Ye1jBw5Un5+fmrdurUWL14sq9Vaot/lZmEoFAAAwG0uJiZGr776qvr06SNJCg4O1o8//qi3335bgwcPtvWLiopSly5dJEljx45V//79FR8fr/vvv1+SNHToUL377rt2z+3i4qLFixfLw8ND9957r2JjYzV+/HhNmzZNubm5mjFjhr766iuFhYVJkurVq6dt27bp7bffVocOHWzPExsbq4cffth2v1q1agoNDbXdnzZtmtauXatPPvlEo0aNUrVq1eTs7CwvLy8FBASUeJ9UqVJFCxcutA2Bev/995Wfn6+FCxfazn4sWbJEvr6+SkhI0COPPFLo8+zfv7/I1/H29i7y8djYWD344IPy8PDQl19+qeeee05ZWVkaM2ZMiX+n8kawAAAAuI1duHBBx48f19ChQzV8+HBb+5UrV+Tj42PXt2nTpraf/f39JUkhISF2bWfOnLHbJjQ0VB4eHrb7YWFhysrKUkpKirKysnTx4kW7wCBdndPQvHlzu7ZWrVrZ3c/KytKUKVO0fv16paam6sqVK7p06ZLtjIVRISEhdvMqDhw4oMTERHl5edn1u3z5so4fP37D56lfv76hOiZPnmz7uXnz5rpw4YJefvllggUAAAAcS1ZWliRpwYIFatOmjd1jzs7OdvcrV65s+/nat/bXt+Xn55f4tdevX6/atWvbPebq6mp3v0qVKnb3o6KitHHjRr3yyiuqX7++3N3d9fjjjxc5LEmSnJycCgwlys3NLdDv+tfLyspSy5YttXz58gJ9q1evfsPX+6NJ8QMHDtT8+fOL7PN7bdq00bRp05SdnV1gH5mNYAEAAHAb8/f3V61atXTixAkNGDCgzJ//wIEDunTpktzd3SVJO3fulKenpwIDA1WtWjW5uroqOTnZbthTcWzfvl1DhgzRY489Junqgf/1E6ldXFyUl5dn11a9enWlpaXJarXawtEfDVeSpBYtWmjVqlWqUaPGHw5f+j2jQ6EKe76qVas6XKiQCBYAAAC3valTp2rMmDHy8fFR165dlZ2drT179ujXX39VZGSkoefOycnR0KFDNWnSJCUlJSkmJkajRo2Sk5OTvLy8FBUVpYiICOXn5+uBBx5QRkaGtm/fLm9vb7v5Hddr0KCB1qxZo549e8pisWjy5MkFzpYEBQVpy5YtevLJJ+Xq6io/Pz917NhRZ8+e1axZs/T4449rw4YN+vzzz//wAH/AgAF6+eWX1atXL8XGxqpOnTo6deqU1qxZowkTJqhOnTqFbmdkKNS//vUvpaen609/+pPc3Ny0ceNGzZgxQ1FRUaV+zvLEVaEAAABuc8OGDdPChQu1ZMkShYSEqEOHDnr33XcVHBxs+LkfeughNWjQQO3bt1e/fv306KOP2i3GN23aNE2ePFlxcXFq1KiRunbtqvXr1//ha8+ePVtVq1ZV27Zt1bNnT3Xp0kUtWrSw6xMbG6ukpCTdddddtuFKjRo10ptvvql58+YpNDRUu3btKtaBuoeHh7Zs2aI777xTffr0UaNGjTR06FBdvny5xGcdiqty5cqaN2+ewsLC1KxZM7399tuaPXu2YmJiyuX1jLJYHfV6VeUkMzNTPj4+ysjIKLc3AYDbzBSfP+5j65tRfnUAuGkuX76skydPKjg42GHXFHAEQ4YM0fnz57Vu3TqzS0ERino/l+TYmTMWAAAAAAwjWAAAAAAwjMnbAAAAKBfXL5aHWxtnLAAAAAAYRrAAAAAAYBjBAgAAoJRus4tr4hZVVu9jggUAAEAJOTs7S7q6+BtQ0V28eFHS1XUzjGDyNgAAQAlVqlRJHh4eOnv2rCpXriwnJ76rRcVjtVp18eJFnTlzRr6+vrbAXFoECwAAgBKyWCyqWbOmTp48qVOnTpldDmCIr6+vAgICDD8PwQIAAKAUXFxc1KBBA4ZDoUKrXLmy4TMV1xAsAAAASsnJyUlubm5mlwE4BAYEAgAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADDM9WMybN09BQUFyc3NTmzZttGvXriL7z5kzR/fcc4/c3d0VGBioiIgIXb58+SZVCwAAAKAwpgaLVatWKTIyUjExMdq7d69CQ0PVpUsXnTlzptD+K1as0AsvvKCYmBgdPnxYixYt0qpVq/Tiiy/e5MoBAAAA/J6pwWL27NkaPny4wsPD1bhxY82fP18eHh5avHhxof2/+eYb3X///XrqqacUFBSkRx55RP379//DsxwAAAAAypdpwSInJ0ffffedOnfu/L9inJzUuXNn7dixo9Bt2rZtq++++84WJE6cOKHPPvtM3bt3v+HrZGdnKzMz0+4GAAAAoGxVMuuFf/75Z+Xl5cnf39+u3d/fX0eOHCl0m6eeeko///yzHnjgAVmtVl25ckUjRowocihUXFycpk6dWqa1AwAAALBn+uTtkkhISNCMGTP05ptvau/evVqzZo3Wr1+vadOm3XCbiRMnKiMjw3ZLSUm5iRUDAAAAtwfTzlj4+fnJ2dlZ6enpdu3p6ekKCAgodJvJkyfr6aef1rBhwyRJISEhunDhgv7f//t/eumll+TkVDAnubq6ytXVtex/AQAAAAA2pp2xcHFxUcuWLRUfH29ry8/PV3x8vMLCwgrd5uLFiwXCg7OzsyTJarWWX7EAAAAAimTaGQtJioyM1ODBg9WqVSu1bt1ac+bM0YULFxQeHi5JGjRokGrXrq24uDhJUs+ePTV79mw1b95cbdq0UWJioiZPnqyePXvaAgYAAACAm8/UYNGvXz+dPXtW0dHRSktLU7NmzbRhwwbbhO7k5GS7MxSTJk2SxWLRpEmTdPr0aVWvXl09e/bU9OnTzfoVAAAAAEiyWG+zMUSZmZny8fFRRkaGvL29zS4HwK1gik8J+maUXx0AAJSxkhw7V6irQgEAAABwTAQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIaZHizmzZunoKAgubm5qU2bNtq1a1eR/c+fP6+RI0eqZs2acnV11d13363PPvvsJlULAAAAoDCVzHzxVatWKTIyUvPnz1ebNm00Z84cdenSRUePHlWNGjUK9M/JydHDDz+sGjVqaPXq1apdu7ZOnTolX1/fm188AAAAABtTg8Xs2bM1fPhwhYeHS5Lmz5+v9evXa/HixXrhhRcK9F+8eLHOnTunb775RpUrV5YkBQUF3cySAQAAABTCtKFQOTk5+u6779S5c+f/FePkpM6dO2vHjh2FbvPJJ58oLCxMI0eOlL+/v5o0aaIZM2YoLy/vZpUNAAAAoBCmnbH4+eeflZeXJ39/f7t2f39/HTlypNBtTpw4oa+//loDBgzQZ599psTERD333HPKzc1VTExModtkZ2crOzvbdj8zM7PsfgkAAAAAkhxg8nZJ5Ofnq0aNGnrnnXfUsmVL9evXTy+99JLmz59/w23i4uLk4+NjuwUGBt7EigEAAIDbg2nBws/PT87OzkpPT7drT09PV0BAQKHb1KxZU3fffbecnZ1tbY0aNVJaWppycnIK3WbixInKyMiw3VJSUsrulwAAAAAgycRg4eLiopYtWyo+Pt7Wlp+fr/j4eIWFhRW6zf3336/ExETl5+fb2o4dO6aaNWvKxcWl0G1cXV3l7e1tdwMAAABQtkwdChUZGakFCxZo6dKlOnz4sJ599llduHDBdpWoQYMGaeLEibb+zz77rM6dO6exY8fq2LFjWr9+vWbMmKGRI0ea9SsAAAAAUCknb2/atEmdOnUy/OL9+vXT2bNnFR0drbS0NDVr1kwbNmywTehOTk6Wk9P/sk9gYKC++OILRUREqGnTpqpdu7bGjh2r559/3nAtAAAAAErPYrVarSXdyNXVVXXq1FF4eLgGDx5coSZEZ2ZmysfHRxkZGQyLAlA2pviUoG9G+dUBAEAZK8mxc6mGQp0+fVqjRo3S6tWrVa9ePXXp0kUffvjhDSdQAwAAALi1lSpY+Pn5KSIiQvv379e3336ru+++W88995xq1aqlMWPG6MCBA2VdJwAAAAAHZnjydosWLTRx4kSNGjVKWVlZWrx4sVq2bKl27drphx9+KIsaAQAAADi4UgeL3NxcrV69Wt27d1fdunX1xRdf6I033lB6eroSExNVt25d9e3btyxrBQAAAOCgSnVVqNGjR+uDDz6Q1WrV008/rVmzZqlJkya2x6tUqaJXXnlFtWrVKrNCAQAAADiuUgWLH3/8Uf/3f/+nPn36yNXVtdA+fn5+2rRpk6HiAAAAAFQMpRoKFRMTo759+xYIFVeuXNGWLVskSZUqVVKHDh2MVwgAAADA4ZXqjEWnTp2UmpqqGjVq2LVnZGSoU6dOysvLK5PiAMAMQS+sL1H/JLdyKgQAgAqkVGcsrFarLBZLgfZffvlFVapUMVwUAAAAgIqlRGcs+vTpI0myWCwaMmSI3VCovLw8HTx4UG3bti3bCgEAAAA4vBIFCx8fH0lXz1h4eXnJ3d3d9piLi4v+9Kc/afjw4WVbIQAAAACHV6JgsWTJEklSUFCQoqKiGPYEAAAAQFIpJ2/HxMSUdR0AAAAAKrBiB4sWLVooPj5eVatWVfPmzQudvH3N3r17y6Q4AAAAABVDsYNFr169bJO1e/fuXV71AAAAAKiAih0sfj/8iaFQAAAAAH6vVOtYAAAAAMDvFfuMRdWqVYucV/F7586dK3VBAAAAACqeYgeLOXPmlGMZAAAAACqyYgeLwYMHl2cdAAAAACqwYgeLzMxMeXt7234uyrV+AAAAAG4PJZpjkZqaqho1asjX17fQ+RZWq1UWi0V5eXllWiQAAAAAx1bsYPH111+rWrVqkqRNmzaVW0EAAAAAKp5iB4sOHToU+jMAAAAAFDtYXO/XX3/VokWLdPjwYUlS48aNFR4ebjurAQAAAOD2UaoF8rZs2aKgoCDNnTtXv/76q3799VfNnTtXwcHB2rJlS1nXCAAAAMDBleqMxciRI9WvXz+99dZbcnZ2liTl5eXpueee08iRI3Xo0KEyLRIAAACAYyvVGYvExET97W9/s4UKSXJ2dlZkZKQSExPLrDgAAAAAFUOpgkWLFi1scyt+7/DhwwoNDTVcFAAAAICKpdhDoQ4ePGj7ecyYMRo7dqwSExP1pz/9SZK0c+dOzZs3TzNnziz7KgEAAAA4NIvVarUWp6OTk5MsFov+qLujL5CXmZkpHx8fZWRksEI4gEIFvbC+RP2T3J4qfucpGSWsBgAA85Tk2LnYZyxOnjxpuDAAAAAAt6ZiB4u6deuWZx0AAAAAKrBSL5AnST/++KOSk5OVk5Nj1/7oo48aKgoAAABAxVKqYHHixAk99thjOnTokN28C4vFIkkOPccCAAAAQNkr1eVmx44dq+DgYJ05c0YeHh764YcftGXLFrVq1UoJCQllXCIAAAAAR1eqMxY7duzQ119/LT8/Pzk5OcnJyUkPPPCA4uLiNGbMGO3bt6+s6wQAAADgwEp1xiIvL09eXl6SJD8/P/3000+Srk7wPnr0aNlVBwAAAKBCKNUZiyZNmujAgQMKDg5WmzZtNGvWLLm4uOidd95RvXr1yrpGAAAAAA6uVMFi0qRJunDhgiQpNjZWf/7zn9WuXTvdcccdWrVqVZkWCAAAAMDxlSpYdOnSxfZz/fr1deTIEZ07d05Vq1a1XRkKAAAAwO3D0DoWkpSSkiJJCgwMNFwMAAAAgIqpVJO3r1y5osmTJ8vHx0dBQUEKCgqSj4+PJk2apNzc3LKuEQAAAICDK9UZi9GjR2vNmjWaNWuWwsLCJF29BO2UKVP0yy+/6K233irTIgEAAAA4tlIFixUrVmjlypXq1q2bra1p06YKDAxU//79CRYAAADAbaZUQ6FcXV0VFBRUoD04OFguLi5GawIAAABQwZQqWIwaNUrTpk1Tdna2rS07O1vTp0/XqFGjyqw4AAAAABVDsYdC9enTx+7+V199pTp16ig0NFSSdODAAeXk5Oihhx4q2woBAAAAOLxiBwsfHx+7+3/5y1/s7nO5WQAAAOD2VexgsWTJkvKsAwAAAEAFZmiBvLNnz+ro0aOSpHvuuUfVq1cvk6IAAAAAVCylmrx94cIFPfPMM6pZs6bat2+v9u3bq1atWho6dKguXrxY1jUCAAAAcHClChaRkZHavHmz/vWvf+n8+fM6f/68Pv74Y23evFl/+9vfyrpGAAAAAA6uVEOhPvroI61evVodO3a0tXXv3l3u7u564oknWCAPAAAAuM2U6ozFxYsX5e/vX6C9Ro0aDIUCAAAAbkOlChZhYWGKiYnR5cuXbW2XLl3S1KlTFRYWVmbFAQAAAKgYSjUUas6cOeratWuBBfLc3Nz0xRdflGmBAAAAABxfqYJFSEiI/v3vf2v58uU6cuSIJKl///4aMGCA3N3dy7RAAAAAAI6vxMEiNzdXDRs21Keffqrhw4eXR00AAAAAKpgSz7GoXLmy3dwKAAAAACjV5O2RI0fqH//4h65cuVLW9QAAAACogEo1x2L37t2Kj4/Xl19+qZCQEFWpUsXu8TVr1pRJcQAAAAAqhlIFC19fX/3lL38p61oAAAAAVFAlChb5+fl6+eWXdezYMeXk5OjBBx/UlClTuBIUAAAAcJsr0RyL6dOn68UXX5Snp6dq166tuXPnauTIkeVVGwAAAIAKokTBYtmyZXrzzTf1xRdfaN26dfrXv/6l5cuXKz8/v7zqAwAAAFABlChYJCcnq3v37rb7nTt3lsVi0U8//VTmhQEAAACoOEoULK5cuSI3Nze7tsqVKys3N7dMiwIAAABQsZRo8rbVatWQIUPk6upqa7t8+bJGjBhhd8lZLjcLAAAA3F5KFCwGDx5coG3gwIFlVgwAAACAiqlEwWLJkiXlVQcAAACACqxEcywAAAAAoDAECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGOYQwWLevHkKCgqSm5ub2rRpo127dhVru5UrV8pisah3797lWyAAAACAIpkeLFatWqXIyEjFxMRo7969Cg0NVZcuXXTmzJkit0tKSlJUVJTatWt3kyoFAAAAcCOmB4vZs2dr+PDhCg8PV+PGjTV//nx5eHho8eLFN9wmLy9PAwYM0NSpU1WvXr2bWC0AAACAwpgaLHJycvTdd9+pc+fOtjYnJyd17txZO3bsuOF2sbGxqlGjhoYOHXozygQAAADwByqZ+eI///yz8vLy5O/vb9fu7++vI0eOFLrNtm3btGjRIu3fv79Yr5Gdna3s7Gzb/czMzFLXCwAAAKBwpg+FKonffvtNTz/9tBYsWCA/P79ibRMXFycfHx/bLTAwsJyrBAAAAG4/pp6x8PPzk7Ozs9LT0+3a09PTFRAQUKD/8ePHlZSUpJ49e9ra8vPzJUmVKlXS0aNHddddd9ltM3HiREVGRtruZ2ZmEi4AAACAMmZqsHBxcVHLli0VHx9vu2Rsfn6+4uPjNWrUqAL9GzZsqEOHDtm1TZo0Sb/99ptef/31QgODq6urXF1dy6V+AAAAAFeZGiwkKTIyUoMHD1arVq3UunVrzZkzRxcuXFB4eLgkadCgQapdu7bi4uLk5uamJk2a2G3v6+srSQXaAQAAANw8pgeLfv366ezZs4qOjlZaWpqaNWumDRs22CZ0Jycny8mpQk0FAQAAAG47FqvVajW7iJspMzNTPj4+ysjIkLe3t9nlAHBAQS+sL1H/JLenit95SkYJqwEAwDwlOXbmVAAAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwrJLZBQAAAKD8BL2wvkT9k2b2KKdKcKvjjAUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCsktkFAMDtJGRpSIn6Hxp8qJwqAQCgbHHGAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYay8DQAAgFIJWRpSov6HBh8qp0rgCDhjAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCHCBbz5s1TUFCQ3Nzc1KZNG+3ateuGfRcsWKB27dqpatWqqlq1qjp37lxkfwAAAADlz/RgsWrVKkVGRiomJkZ79+5VaGiounTpojNnzhTaPyEhQf3799emTZu0Y8cOBQYG6pFHHtHp06dvcuUAAAAArjE9WMyePVvDhw9XeHi4GjdurPnz58vDw0OLFy8utP/y5cv13HPPqVmzZmrYsKEWLlyo/Px8xcfH3+TKAQAAAFxjarDIycnRd999p86dO9vanJyc1LlzZ+3YsaNYz3Hx4kXl5uaqWrVqhT6enZ2tzMxMuxsAAACAsmVqsPj555+Vl5cnf39/u3Z/f3+lpaUV6zmef/551apVyy6c/F5cXJx8fHxst8DAQMN1AwAAALBn+lAoI2bOnKmVK1dq7dq1cnNzK7TPxIkTlZGRYbulpKTc5CoBAACAW18lM1/cz89Pzs7OSk9Pt2tPT09XQEBAkdu+8sormjlzpr766is1bdr0hv1cXV3l6upaJvUCAAAAKJypZyxcXFzUsmVLu4nX1yZih4WF3XC7WbNmadq0adqwYYNatWp1M0oFAAAAUARTz1hIUmRkpAYPHqxWrVqpdevWmjNnji5cuKDw8HBJ0qBBg1S7dm3FxcVJkv7xj38oOjpaK1asUFBQkG0uhqenpzw9PU37PQAAAIDbmenBol+/fjp79qyio6OVlpamZs2aacOGDbYJ3cnJyXJy+t+Jlbfeeks5OTl6/PHH7Z4nJiZGU6ZMuZmlAwAAAPgv04OFJI0aNUqjRo0q9LGEhAS7+0lJSeVfEAAAAIASqdBXhQIAAADgGAgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADCNYAAAAADCMYAEAAADAMIIFAAAAAMMIFgAAAAAMI1gAAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwrJLZBaDshSwNKVH/Q4MPlVMlAAAAuF1wxgIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhWyewCAAAAgNtJyNKQYvc9NPhQOVZStggWAACHVpI/wFLF+iMMALcShkIBAAAAMIxgAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjKtCAeKqMwAAAEZxxgIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhnG5WZMEvbC+RP2TZvYop0oAAAAA4zhjAQAAAMAwggUAAAAAwwgWAAAAAAwjWAAAAAAwjGABAAAAwDCCBQAAAADDCBYAAAAADGMdCwAAbkEhS0OK3ffQ4EPlWAmA2wXBAkCpceAC4FZSks80ic814HoMhQIAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIYRLAAAAAAYRrAAAAAAYBjBAgAAAIBhBAsAAAAAhhEsAAAAABhGsAAAAABgGMECAAAAgGEECwAAAACGVTK7AEmaN2+eXn75ZaWlpSk0NFT/93//p9atW9+w/z//+U9NnjxZSUlJatCggf7xj3+oe/fuN7FiAACAW9QUn+L3Db6z/OpAhWP6GYtVq1YpMjJSMTEx2rt3r0JDQ9WlSxedOXOm0P7ffPON+vfvr6FDh2rfvn3q3bu3evfure+///4mVw4AAADgGtODxezZszV8+HCFh4ercePGmj9/vjw8PLR48eJC+7/++uvq2rWrxo8fr0aNGmnatGlq0aKF3njjjZtcOQAAAIBrTB0KlZOTo++++04TJ060tTk5Oalz587asWNHodvs2LFDkZGRdm1dunTRunXryrNUAEARgl5YX6L+STN7lFMlAFA2SvK5xmfaVaYGi59//ll5eXny9/e3a/f399eRI0cK3SYtLa3Q/mlpaYX2z87OVnZ2tu1+RkaGJCkzM9NI6YblZ18sUf+S1Jt3Ka/cnttMTWK+KFH/76d2KXbfW3WflbeS7LeKtM9K/O/TYi1231v1vcZnmuO5Vf99lqdb9b3GZ1rplGS/lfT3qkj/Pq+9vtX6x+8Lh5i8XZ7i4uI0derUAu2BgYEmVFN6PnPK8bmfLcEkrQqEfeZYbuV9VrLf7HDJnvsW3W/8+3Qs7LPSuVX3G59pJXc7fKb99ttv8vEpuhZTg4Wfn5+cnZ2Vnp5u156enq6AgIBCtwkICChR/4kTJ9oNncrPz9e5c+d0xx13yGKxGPwNylZmZqYCAwOVkpIib29vs8upENhnJcc+Kx32W8mxz0qOfVY67LeSY5+V3O26z6xWq3777TfVqlXrD/uaGixcXFzUsmVLxcfHq3fv3pKuHvjHx8dr1KhRhW4TFham+Ph4jRs3zta2ceNGhYWFFdrf1dVVrq6udm2+vr5lUX658fb2vq3esGWBfVZy7LPSYb+VHPus5NhnpcN+Kzn2Wcndjvvsj85UXGP6UKjIyEgNHjxYrVq1UuvWrTVnzhxduHBB4eHhkqRBgwapdu3aiouLkySNHTtWHTp00KuvvqoePXpo5cqV2rNnj9555x0zfw0AAADgtmZ6sOjXr5/Onj2r6OhopaWlqVmzZtqwYYNtgnZycrKcnP53Vdy2bdtqxYoVmjRpkl588UU1aNBA69atU5MmTcz6FQAAAIDbnunBQpJGjRp1w6FPCQkJBdr69u2rvn37lnNVN5+rq6tiYmIKDN3CjbHPSo59Vjrst5Jjn5Uc+6x02G8lxz4rOfbZH7NYi3PtKAAAAAAogukrbwMAAACo+AgWAAAAAAwjWAAAAAAwjGABAAAAwDCChUmuXLmiZcuWFVhFHAAAAKiIuCqUiTw8PHT48GHVrVvX7FIqlMGDB2vo0KFq37692aVUGPXq1dPu3bt1xx132LWfP39eLVq00IkTJ0yqzLF88sknxe776KOPlmMluN3l5eXp0KFDqlu3rqpWrWp2OaigMjMzi933dltJuri2bNlS5OMci9hziHUsbletW7fW/v37CRYllJGRoc6dO6tu3boKDw/X4MGDVbt2bbPLcmhJSUnKy8sr0J6dna3Tp0+bUJFj6t27t919i8Wi33/3YrFYbD8Xtj8hLV26VH5+furRo4ckacKECXrnnXfUuHFjffDBB3ze3cC4ceMUEhKioUOHKi8vTx06dNA333wjDw8Pffrpp+rYsaPZJTqk1atX68MPP1RycrJycnLsHtu7d69JVTkOX19fu8+tovCZVrjC/u3xt+DGGAploueee06RkZF64403tGPHDh08eNDuhsKtW7dOp0+f1rPPPqtVq1YpKChI3bp10+rVq5Wbm2t2eQ7lk08+sX0L/8UXX9juf/LJJ1q7dq2mTZumoKAgc4t0IPn5+bbbl19+qWbNmunzzz/X+fPndf78eX322Wdq0aKFNmzYYHapDmvGjBlyd3eXJO3YsUPz5s3TrFmz5Ofnp4iICJOrc1yrV69WaGioJOlf//qXTp48qSNHjigiIkIvvfSSydU5prlz5yo8PFz+/v7at2+fWrdurTvuuEMnTpxQt27dzC7PIWzatElff/21vv76ay1evFg1atTQhAkTtHbtWq1du1YTJkyQv7+/Fi9ebHapDuvXX3+1u505c0YbNmzQfffdpy+//NLs8hyPFaaxWCwFbk5OTrb/oni+++4766hRo6xubm5WPz8/67hx46zHjh0zuyyHUNh77NrNxcXFevfdd1v/9a9/mV2mQ7r33nutW7duLdC+ZcsWa8OGDU2oqGJwd3e3njp1ymq1Wq0TJkywPv3001ar1Wr9/vvvrX5+fmaW5tBcXV2tKSkpVqvVah0+fLh17NixVqvVaj1x4oTVy8vLxMoc1z333GNdsWKF1Wq1Wj09Pa3Hjx+3Wq1W6+TJk60jR440szSH9OCDD9r21+8tX77c2qFDh5tfUAWXkJBgbdGihdllOBzOWJjo5MmTBW4nTpyw/Rd/LDU1VRs3btTGjRvl7Oys7t2769ChQ2rcuLFee+01s8sz3bVv3+vWrauzZ8/afSOfnZ2to0eP6s9//rPZZTqk48ePy9fXt0C7j4+PkpKSbno9FYWnp6d++eUXSdKXX36phx9+WJLk5uamS5cumVmaQ/P399ePP/6ovLw8bdiwwbbfLl68KGdnZ5Orc0zJyclq27atJMnd3V2//fabJOnpp5/WBx98YGZpDmnHjh1q1apVgfZWrVpp165dJlRUsfn7++vo0aNml+FwmGNhIsYal05ubq4++eQTLVmyRF9++aWaNm2qcePG6amnnrJNPlu7dq2eeeYZhl7o6v6qV6+ezp07V2DyNm7svvvuU2RkpN577z35+/tLktLT0zV+/Hi1bt3a5Ooc18MPP6xhw4apefPmOnbsmLp37y5J+uGHHxh2V4Tw8HA98cQTqlmzpiwWizp37ixJ+vbbb9WwYUOTq3NMAQEBOnfunOrWras777xTO3fuVGhoqE6ePGk3NwpXBQYGasGCBZo1a5Zd+8KFCxUYGGhSVY7v+qHpVqtVqampmjlzppo1a2ZOUQ6MYGGy9957T/Pnz9fJkye1Y8cO1a1bV3PmzFFwcLB69epldnkOqWbNmsrPz1f//v21a9euQv9hd+rUqdBvm29HlStXZs5OKSxatEh9+vTRnXfeafujm5KSogYNGmjdunXmFufA5s2bp0mTJiklJUUfffSRLcx+99136t+/v8nVOa4pU6aoSZMmSklJUd++feXq6ipJcnZ21gsvvGBydY7pwQcf1CeffKLmzZsrPDxcERERWr16tfbs2aM+ffqYXZ7Dee211/SXv/xFn3/+udq0aSNJ2rVrl/7973/ro48+Mrk6x9WsWbMCF/KQpD/96U/MTSkEl5s10VtvvaXo6GiNGzdO06dP1/fff6969erp3Xff1dKlS7Vp0yazS3RI7733nvr27Ss3NzezS6kwIiIi5OrqqpkzZ5pdSoVitVq1ceNGHTlyRJLUqFEjde7cudhXWQFK4/Lly3y+FcO1YZ2VKl39jnTlypX65ptv1KBBA/31r3+Vi4uLyRU6nv/85z966623dPjwYUlXP9NGjBjBGYsinDp1yu6+k5OTqlevzr/RGyBYmKhx48aaMWOGevfuLS8vLx04cED16tXT999/r44dO+rnn382u0SHk5ubK3d3d+3fv19NmjQxu5wKY/To0Vq2bJkaNGigli1bqkqVKnaPz54926TKHBPvM2O2bt2qt99+WydOnNA///lP1a5dW++9956Cg4P1wAMPmF2eQ8rLy9OMGTM0f/58paen69ixY6pXr54mT56soKAgDR061OwSUYHl5uaqa9eumj9/vho0aGB2ObiFMXnbRCdPnlTz5s0LtLu6uurChQsmVOT4KleurDvvvJPrRpfQ999/rxYtWsjLy0vHjh3Tvn37bLf9+/ebXZ7D4X1Weh999JG6dOkid3d37d27V9nZ2ZKurj8zY8YMk6tzXNOnT9e7776rWbNm2X3T3qRJEy1cuNDEyhxXvXr1FB4ebnuPXfPzzz+rXr16JlXlmBgSa8zmzZvVs2dP1a9fX/Xr19ejjz6qrVu3ml2WQyJYmCg4OLjQg7oNGzaoUaNGN7+gCuKll17Siy++qHPnzpldSoWxadOmG96+/vprs8tzSLzPSufvf/+75s+frwULFqhy5cq29vvvv58Fy4qwbNkyvfPOOxowYIDdVaBCQ0NtQ/FgLykpSdu3b1e7du2UlpZma8/LyyswfAXSwIEDtWjRIrPLqHDef/99de7cWR4eHhozZozGjBkjd3d3PfTQQ1qxYoXZ5TkcJm+bKDIyUiNHjtTly5dltVq1a9cuffDBB4qLi+MbqiK88cYbSkxMVK1atVS3bt0Cw3o4eCnaf/7zH0lSnTp1TK7EsfE+K52jR4+qffv2Bdp9fHx0/vz5m19QBXH69GnVr1+/QHt+fj4Lf96AxWLRhg0bFBUVpZYtW2rdunW67777zC7LYV25ckWLFy/WV199xZDYEpg+fbpmzZpld5XJMWPGaPbs2Zo2bZqeeuopE6tzPAQLEw0bNkzu7u6aNGmSLl68qKeeekq1atXS66+/rieffNLs8hxW7969zS6hwsnPz9ff//53vfrqq8rKypIkeXl56W9/+5teeuklOTlx8vJ6vM9KJyAgQImJiQUuLbtt2zaGpxShcePG2rp1a4HLkK9evbrQIbO4enEFT09PrVmzRhMnTlSHDh30zjvv2NYAgb1rQ2Il6dixY3aPcUGKGztx4oR69uxZoP3RRx/Viy++aEJFjo1gYbIBAwZowIABunjxorKyslSjRg2zS3J4MTExZpdQ4bz00ktatGiRZs6cqfvvv1/S1QO9KVOm6PLly5o+fbrJFToe3melM3z4cI0dO1aLFy+WxWLRTz/9pB07digqKkqTJ082uzyHFR0drcGDB+v06dPKz8/XmjVrdPToUS1btkyffvqp2eU5pN8fDMfFxenee+/V8OHDuazxDXClydIJDAxUfHx8gTOKX331FVfTKgRXhTLRpUuXZLVa5eHhIenqJc3Wrl2rxo0b65FHHjG5Osd2/vx5rV69WsePH9f48eNVrVo17d27V/7+/qpdu7bZ5TmcWrVqaf78+Xr00Uft2j/++GM999xzOn36tEmV4VZjtVo1Y8YMxcXF6eLFi5KuXpAiKipK06ZNM7k6x7Z161bFxsbqwIEDysrKUosWLRQdHc3fgxtwcnJSWlqa3RdyO3bs0GOPPaazZ89y8QWUibfeekvjxo3TM888Y1vpffv27Xr33Xf1+uuv669//avJFToWgoWJHnnkEfXp00cjRozQ+fPndc8998jFxUU///yzZs+erWeffdbsEh3SwYMH1blzZ/n4+CgpKUlHjx5VvXr1NGnSJCUnJ2vZsmVml+hw3NzcdPDgQd1999127UePHlWzZs106dIlkypzXHl5eXrttdf04YcfKjk5WTk5OXaPM6m7aDk5OUpMTFRWVpYaN24sT09Ps0vCbSI9PV1HjhxRhw4dzC7F4ezZs+eGn2lr1qwxqSrHt3btWr366qt263+MHz+ehYwLwcBqE+3du1ft2rWTdHUcbUBAgE6dOqVly5Zp7ty5JlfnuCIjIzVkyBD9+9//tlugpnv37tqyZYuJlTmu0NBQvfHGGwXa33jjDYWGhppQkeObOnWqZs+erX79+ikjI0ORkZHq06ePnJycNGXKFLPLc3guLi5q3LixWrduTagohmHDhikhIcHsMiqU2NjYQq9q5+npqc2bN5tQkWNbuXKl2rZtq8OHD2vt2rXKzc3VDz/8oK+//lo+Pj5ml+ewBg8erDvuuEPbtm3TL7/8ol9++UXbtm0jVNwAZyxM5OHhoSNHjujOO+/UE088oXvvvVcxMTFKSUnRPffcYxtGAHs+Pj7au3ev7rrrLruFBU+dOqV77rlHly9fNrtEh7N582b16NFDd955p8LCwiRdHTKQkpKizz77zBZw8T933XWX5s6dqx49esjLy0v79++3te3cuZPLDN7AhQsXNHPmTMXHx+vMmTPKz8+3e/zEiRMmVebYevXqpS+++ELVq1fXk08+qQEDBqhZs2Zml+XQnJycVLlyZcXFxSkyMtLWnp6erlq1ajEU6jpNmzbVX//6V40cOdL2tzM4OFh//etfVbNmTU2dOtXsEh1S79699dlnn6lu3boKDw/XkCFDVKtWLbPLclicsTBR/fr1tW7dOqWkpOiLL76wjaM9c+aMvL29Ta7Ocbm6uiozM7NA+7Fjx1S9enUTKnJ8HTp00LFjx/TYY4/p/PnzOn/+vPr06aOjR48SKm4gLS1NISEhkq5+A5qRkSFJ+vOf/6z169ebWZpDGzZsmBYtWqR27dpp1KhRGjt2rN0Nhfv444+VmpqqyZMna/fu3WrZsqXuvfdezZgxQ0lJSWaX57CWLVumGTNmKDw8vMDQHtg7fvy4evToIenqGcULFy7IYrEoIiJC77zzjsnVOa5169bp9OnTevbZZ7Vq1SrVrVtX3bp10z//+U8uBV0YK0zzz3/+01q5cmWrk5OTtXPnzrb2GTNmWLt27WpiZY5t6NCh1t69e1tzcnKsnp6e1hMnTlhPnTplbd68uXXs2LFml+cwHnvsMWtGRobVarValy5dar18+bLJFVUsd999t3Xnzp1Wq9Vqvf/++61xcXFWq9VqXblypbV69epmlubQfHx8rNu2bTO7jAovJSXFOmvWLGvDhg2tzs7OZpfjkCwWizU9Pd2amJhobdSokTUsLMyanp5uTUtLszo5OZldnsOpXbu29eDBg1ar1WoNCQmxrlixwmq1Wq3ffPON1dvb28zSKpTvvvvOOmrUKKubm5vVz8/POm7cOOuxY8fMLsthcMbCRI8//riSk5O1Z88effHFF7b2hx56SK+99pqJlTm2a2sx1KhRQ5cuXVKHDh1Uv359eXl5cdnU3/n000914cIFSVJ4eLjtG3cUz2OPPab4+HhJ0ujRozV58mQ1aNBAgwYN0jPPPGNydY6ratWqqlatmtllVGi5ubnas2ePvv32WyUlJcnf39/skhzStcvN3nXXXdq5c6e8vb3VsmVL7dmzx+TKHFP79u21ceNGSVLfvn01duxY2+V5H3roIZOrqxhSU1O1ceNGbdy4Uc7OzurevbsOHTqkxo0bc9z2X8yxcBCshlxy27Zt08GDB22XZezcubPZJTmUpk2bqkWLFurUqZPCw8M1d+7cGw6xGzRo0E2uruLZuXOnvvnmGzVo0KDQxZJw1fvvv6+PP/5YS5cutV1KG8WzadMmrVixQh999JHy8/PVp08fDRgwQA8++CALmBXi+svN5ufna9y4cXrrrbeUn5/PHIvrnDt3TpcvX1atWrWUn5+vWbNm2T7TJk2apKpVq5pdokPKzc3VJ598oiVLlujLL79U06ZNNWzYMD311FO2v6lr167VM888o19//dXkas1HsDARqyGXTkpKCovSFMP27dv1t7/9TcePH9e5c+fk5eVV6MGJxWLh0qkwpHnz5nbvrcTERFmtVgUFBaly5cp2fffu3Xuzy6sQateurXPnzqlr164aMGCAevbsKVdXV7PLcmhLly7Vk08+WWA/LVmyRFu2bNGSJUtMqgy3Ej8/P+Xn56t///4aPnx4oRdVOH/+vJo3b66TJ0/e/AIdDMHCRBMnTtSiRYs0derUAqshDx8+nGE9N+Ds7KwHHnhAAwcO1OOPP863LMVQ2EJSKNqdd96pjh07qkOHDurYsaPuuusus0tyWCW5mgwrmhduwYIF6tu3r3x9fc0uBbeoQYMGqVOnTmrfvj2fZyXw3nvvqW/fvnaXt8eNESxMxGrIpbNv3z6tWLFCK1eu1NmzZ9W1a1cNHDiQb/iu06dPH7377rvy9vbW0qVL9cQTT8jd3d3ssiqM999/X1u2bFFCQoISExNVu3ZtdejQwRY0GjRoYHaJuEUxNPbG5s6dq//3//6f3NzcilzvyWKxaPTo0TexMsc3bNgwbdmyxe7z7NqXJ3yeoawQLEzEasjGWK1WJSQkFBiTvHjxYrNLcwguLi46deqUatasKWdnZ6WmpnLGopRSU1O1efNmffrpp1q1ahXjt4uwe/du5efnq02bNnbt3377rZydndWqVSuTKnNsDI0tnuDgYO3Zs0d33HGHgoODb9jPYrGwZsoNnD59Wlu2bNHmzZu1efNmHTt2TDVr1rQFWsCISmYXcDu7thry9d+6sBpy8VgsFnXq1EmdOnXSs88+q6FDh2rp0qUEi/9q2LChJk6cqE6dOslqterDDz9k8nYJXbx4Udu2bVNCQoI2bdqkffv2qUmTJurYsaPZpTmskSNHasKECQWCxenTp/WPf/xD3377rUmVObaXXnpJixYt0syZMwsMjb18+TJDY//r92PYf//zte9ImeT+x6pWrao77rhDVatWla+vrypVqsQaUCgznLEwEashG/Of//xHK1as0IoVK/T9998rLCxMAwYM0IgRI8wuzSF88803ioyMZPJ2KbVt21b79u1To0aNbMMF2rdvz5yeP+Dp6amDBw+qXr16du0nT55U06ZN9dtvv5lUmWNjaGzpLFq0SK+99pr+/e9/S5IaNGigcePGadiwYSZX5nhefPFFJSQk2D7Xrg2F4nMNZYkzFia6thryvHnzdOTIEUlXx8U/99xzLBdfhLffflsrVqzQtm3b1KhRIw0YMEAff/yx6tata3ZpDqVt27bauXOnpKuTt48dO8ZQqBI4cuSIqlSpooYNG6phw4Zq1KgRf3yLwdXVVenp6QWCRWpqqipV4k/OjZw7d04NGzYs0N6wYUOC/w1ER0dr9uzZGj16tN2XcxEREUpOTlZsbKzJFTqWmTNnqnr16oqJiVGfPn0KDMMGygJnLFDhBAYGqn///howYABDxorp1KlTSk5O1ttvv60TJ07on//8p2rXrq333ntPwcHBeuCBB8wu0eFYrVYdOnRICQkJ2rx5s7Zs2SIXFxd16NBBnTp10vDhw80u0SH1799fqamp+vjjj+Xj4yPp6qUYe/furRo1aujDDz80uULH1KZNG7Vp06bA0NjRo0dr9+7dti8J8D/Vq1fX3Llz1b9/f7v2Dz74QKNHj9bPP/9sUmWO6cCBA9q8ebMSEhK0detW2+dZx44d1bFjR4IGygTB4iY7ePBgsfs2bdq0HCupuKxWq7Zt28ZBcgl89NFHevrppzVgwAC99957+vHHH1WvXj298cYb+uyzz/TZZ5+ZXaJDs1qt+u677/TGG29o+fLlTN4uwunTp9W+fXv98ssvat68uSRp//798vf318aNG1mD5gZuNDQ2OTlZn3/+OUNjC+Hr66vdu3cXuKLRsWPH1Lp1a50/f96cwiqIAwcO6LXXXuMzDWWKYHGTOTk5yWKx6I92u8Vi4R/5DXCQXHLNmzdXRESEBg0aJC8vLx04cED16tXTvn371K1bN6WlpZldosPZu3evEhISlJCQoG3btum3335TSEiIbb5Fr169zC7RYV24cEHLly/XgQMH5O7urqZNm6p///4FFsuDvdOnT+utt97S4cOHJUmNGjViaGwRRo8ercqVK2v27Nl27VFRUbp06ZLmzZtnUmWOyWq1at++fXafa5mZmWratKk6dOig1157zewScQsgWNxkp06dKnZf5gwUjoPkkvPw8NCPP/6ooKAgu3124sQJNW7cWJcvXza7RIdTqVIlNW/e3LZ2Rfv27W1De4DycPnyZR08eFBnzpxRfn6+3WPXT+rG1WCxbNkyBQYG6k9/+pOkq5c1Tk5O1qBBg+yC7PXh43ZUtWpVZWVlKTQ01DYEql27dizKiDLFTLqb7PdhIS4uTv7+/nrmmWfs+ixevFhnz57V888/f7PLqxCOHj2q9u3bF2j38fHh1PcNBAQEKDExUUFBQXbt27ZtKzDJFlJeXp7WrFmjdu3aMWG7FP79739r06ZNhR4gR0dHm1SVY9uwYYMGDRqkX375pcAZbc5gF+77779XixYtJEnHjx+XJPn5+cnPz0/ff/+9rR+XoL3q/fffV7t27W542XGgLBAsTHTt6kbXu/fee/Xkk08SLG6Ag+SSGz58uMaOHavFixfLYrHop59+0o4dOxQVFaXJkyebXZ7DcXZ21hNPPKHDhw8TLEpowYIFevbZZ+Xn56eAgAC7gzqLxUKwuIHRo0erb9++io6Olr+/v9nlVAibNm0yu4QKpUePHrafWd0d5YVgYaK0tDTVrFmzQHv16tWVmppqQkUVAwfJJffCCy8oPz9fDz30kC5evKj27dvL1dVVUVFRGj16tNnlOaQmTZroxIkTRa7ui4L+/ve/a/r06XwxUkLp6emKjIwkVKDcsLo7bgaChYkCAwO1ffv2Agcu27dvZ7JeEThILjmLxaKXXnpJ48ePV2JiorKystS4cWN5enqaXZrD+vvf/66oqChNmzZNLVu2VJUqVeweZzhB4X799Vf17dvX7DIqnMcff1wJCQm66667zC4FtyhWd8fNwORtE82aNUuzZs3Syy+/rAcffFCSFB8frwkTJuhvf/ubJk6caHKFji0nJ4eDZJSb33979/vhPFarlTHvRRg6dKjuu+8+jRgxwuxSKpSLFy+qb9++ql69ukJCQgpcQWvMmDEmVYZbBau742bgjIWJxo8fr19++UXPPfeccnJyJElubm56/vnnCRXF4OLiosaNG5tdBm5RjN8unfr162vy5MnauXMnB8gl8MEHH+jLL7+Um5ubEhISCsxNYb/BKFZ3x83AGQsHkJWVpcOHD8vd3V0NGjSQq6ur2SUBQKkUNSfFYrHoxIkTN7GaiiMgIEBjxozRCy+8wFh3lAtWd8fNQLAAgBs4f/68Fi1aZFuw7N5779UzzzzDehYoc9WqVdPu3buZY4Fyc6PV3VNSUvTZZ5+xujvKBMECAAqxZ88edenSRe7u7mrdurUkaffu3bp06ZK+/PJL2/XzIUVGRmratGmqUqWKIiMjb9jPYrHo1VdfvYmVVRwRERGqXr26XnzxRbNLwS0qOTlZlSpV0rx583TkyBFJ/1vd/cqVK7rzzjtNrhC3AoIFABSiXbt2ql+/vhYsWKBKla5OR7ty5YqGDRumEydOaMuWLSZX6Dg6deqktWvXytfXV506dbphP4vFoq+//vomVlZxjBkzRsuWLVNoaKiaNm1aYG4KK0fDKGdnZ6WmpqpGjRp27b/88otq1KjBBSlQJggWAFAId3d37du3r8Bkxx9//FGtWrXSxYsXTaoMtyICGcqbk5OT0tLSCgSLU6dOqXHjxrpw4YJJleFWwlWhAKAQ3t7eSk5OLhAsUlJS5OXlZVJVuFVxFTKUl2vDEy2Wqyvfe3h42B7Ly8vTt99+q2bNmplUHW41BAsAKES/fv00dOhQvfLKK2rbtq2kq4tXjh8/Xv379ze5OgAonn379km6ugbPoUOH5OLiYnvMxcVFoaGhioqKMqs83GIYCgUA/3Xw4EE1adJETk5OysnJ0fjx4zV//nxduXJFklS5cmU9++yzmjlzJpeFBlChhIeH6/XXX5e3t7fZpeAWRrAAgP/6/eTGevXqaffu3XJ3d9fx48clSXfddZfdMAIAAPA/DIUCgP/y9fXVyZMnVaNGDSUlJSk/P18eHh4KCQkxuzQAABwewQIA/usvf/mLOnTooJo1a8pisahVq1ZydnYutC8rSAMAYI9gAQD/9c4776hPnz5KTEzUmDFjNHz4cK4ABQBAMTHHAgAKER4errlz5xIsAAAoJoIFAAAAAMOczC4AAAAAQMVHsAAAAABgGMECAAAAgGEECwAAAACGESwAAAAAGEawAAAAAGAYwQIAAACAYQQLAAAAAIb9f7XO+v9GO1t4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {
    "id": "d750e989-842a-4cfa-a44b-cf44d6e49163"
   },
   "source": [
    "- We can see that the rescaling via temperature 0.1 results in a sharper distribution, approaching `torch.argmax`, such that the most likely word is almost always selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
    "outputId": "b299c81a-870e-46f8-d356-cd84f25539f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {
    "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b"
   },
   "source": [
    "- The rescaled probabilities via temperature 5 are more uniformly distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
    "outputId": "7ca780df-7d28-404a-c9c2-82869f4afe52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {
    "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7"
   },
   "source": [
    "- Assuming an LLM input \"every effort moves you\", using the approach above can sometimes result in nonsensical texts, such as \"every effort moves you pizza\", 3.2% of the time (32 out of 1000 times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CF-drjVKlHcF",
   "metadata": {
    "id": "CF-drjVKlHcF"
   },
   "source": [
    "- The actual probability of *pizza* is 4.3% and is contained in the rescaled softmax probability\n",
    "tensor (scaled_probas[2][6])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "CamlMndfkxM-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CamlMndfkxM-",
    "outputId": "ad9fd099-ed70-4a4e-8065-670d26321145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010120050137629732, 2.9718297823682922e-36, 4.299796000123024]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(pr[6].item()*100) for pr in scaled_probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "Z3zSoJ8_RMGU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3zSoJ8_RMGU",
    "outputId": "d8bcf0df-ded9-41f6-8126-14ec6df63328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1192, 0.8808])\n",
      "tensor([0.0025, 0.9975])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "logits_1 = torch.tensor([2.0, 4.0])\n",
    "logits_2 = torch.tensor([6.0, 12.0])\n",
    "\n",
    "print(torch.softmax(logits_1, dim=0))\n",
    "print(torch.softmax(logits_2, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NED9Pyk3v-tt",
   "metadata": {
    "id": "NED9Pyk3v-tt"
   },
   "source": [
    "***Conclusion:***\n",
    "\n",
    "\n",
    "> We saw that higher temperature values result in more uniformly distributed next-token probabilities, which result in more diverse outputs as it reduces the likelihood of the model repeatedly selecting the most probable token. This method allows for the exploring of less likely but potentially more interesting and creative paths in the generation process. However, one downside of this approach is that it sometimes leads to grammatically incorrect or completely nonsensical outputs such as every effort moves you pizza.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {
    "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7"
   },
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {
    "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df"
   },
   "source": [
    "- To be able to use higher temperatures to increase output diversity and to reduce the probability of nonsensical sentences, we can restrict the sampled tokens to the top-k most likely tokens:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {
    "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=1000px>\n",
    "\n",
    "- (Please note that the numbers in this figure are truncated to two\n",
    "digits after the decimal point to reduce visual clutter. The values in the Softmax row should add up to 1.0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {
    "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c"
   },
   "source": [
    "- In code, we can implement this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
    "outputId": "afaadac4-fde5-4f6f-de2e-7c821268cf0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
    "outputId": "6bfc4163-782c-4451-9de7-f51e0e1ac00e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1], # Identifies logits less than the minimum in the top 3\n",
    "    input=torch.tensor(float(\"-inf\")), # Assigns –inf to these lower logits\n",
    "    other=next_token_logits # Retains the original logits for all other tokens\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
   "metadata": {
    "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00"
   },
   "source": [
    "> NOTE:  \n",
    ">\n",
    ">  An alternative, slightly more efficient implementation of the previous code cell is the following:\n",
    ">\n",
    "> ```python\n",
    "> new_logits = torch.full_like( # create tensor containing -inf values\n",
    ">    next_token_logits, -torch.inf\n",
    ">)   \n",
    "> new_logits[top_pos] = next_token_logits[top_pos] # copy top k values into the -inf tensor\n",
    "> ```\n",
    "> <br>\n",
    "> For more details, see https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
    "outputId": "7cd70b5b-19ff-42f8-c608-cbede462e383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {
    "id": "56056503-a15d-4315-a3ff-46647a4c7c45"
   },
   "source": [
    "### 5.3.3 Modifying the text generation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {
    "id": "34770423-473d-46f6-a5fa-6b2979564d26"
   },
   "source": [
    "- The previous two subsections introduced temperature sampling and top-k sampling\n",
    "- Let's use these two concepts to modify the `generate_simple` function we used to generate text via the LLM earlier, creating a new `generate` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {
    "id": "8e318891-bcc0-4d71-b147-33ce55febfa3"
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
    "outputId": "a2082d75-5a0f-40aa-a15a-aa665689e6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to go a little wild--I was such a good; and\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IgH_n8X3TXUK",
   "metadata": {
    "id": "IgH_n8X3TXUK"
   },
   "source": [
    "\n",
    "\n",
    "> **Exercise 5.2**\n",
    "Play around with different temperatures and top-k settings. Based on your observations,\n",
    "can you think of applications where lower temperature and top-k settings are\n",
    "desired? Likewise, can you think of applications where higher temperature and top-k\n",
    "settings are preferred? (It’s recommended to also revisit this exercise at the end of\n",
    "the chapter after loading the pretrained weights from OpenAI.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "When using relatively small top-k values (e.g., smaller than 10) and when the temperature is set below 1, the model’s output becomes less random and more deterministic. This setting is useful when we need the generated text to be more predictable, coherent, and closer to the most likely outcomes based on the training data. Applications for such low k and temperature settings include generating formal documents or reports where clarity and accuracy are most important. Other examples of applications include technical analysis or code-generation tasks, where precision is crucial. Also, question answering and educational content require accurate answers where a temperature below 1 is helpful.\n",
    "\n",
    "On the other hand, larger top-k values (e.g., values in the range of 20 to 40) and temperature values above 1 are useful when using LLMs for brainstorming or generating creative content, such as fiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zfW9siliTjRn",
   "metadata": {
    "id": "zfW9siliTjRn"
   },
   "source": [
    "\n",
    "\n",
    "> **Exercise 5.3**\n",
    "What are the different combinations of settings for the generate function to force deterministic behavior, that is, disabling the random sampling such that it always produces the same outputs similar to the generate_simple function?\n",
    "\n",
    "\n",
    "\n",
    "There are multiple ways to force deterministic behavior with the generate function:\n",
    "\n",
    "1. Setting to top_k=None and applying no temperature scaling\n",
    "\n",
    "2. Setting top_k=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {
    "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b"
   },
   "source": [
    "## 5.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {
    "id": "0fc52676-f026-4566-a226-2a90269f9d53"
   },
   "source": [
    "- Training LLMs is computationally expensive, so it's crucial to be able to save and load LLM weights\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-3.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {
    "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82"
   },
   "source": [
    "- The recommended way in PyTorch is to save the model weights, the so-called `state_dict` via by applying the `torch.save` function to the `.state_dict()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {
    "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {
    "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e"
   },
   "source": [
    "- Then we can load the model weights into a new `GPTModel` model instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {
    "id": "9d57d914-60a3-47f1-b499-5352f4c457cb"
   },
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {
    "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1"
   },
   "source": [
    "- It's common to train LLMs with adaptive optimizers like Adam or AdamW instead of regular SGD\n",
    "- These adaptive optimizers store additional parameters for each model weight, so it makes sense to save them as well in case we plan to continue the pretraining later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {
    "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {
    "id": "8a0c7295-c822-43bf-9286-c45abc542868"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GSL4sw-jdpAb",
   "metadata": {
    "id": "GSL4sw-jdpAb"
   },
   "source": [
    "\n",
    "\n",
    "> **Exercise 5.4**\n",
    "After saving the weights, load the model and optimizer in a new Python session or\n",
    "Jupyter notebook file and continue pretraining it for one more epoch using the\n",
    "train_model_simple function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "H4k4ekAmdxcZ",
   "metadata": {
    "id": "H4k4ekAmdxcZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {
    "id": "4194350e-0409-4a63-8ffd-d3a896509032"
   },
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {
    "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec"
   },
   "source": [
    "- Previously, we only trained a small GPT-2 model using a very small short-story book for educational purposes\n",
    "- Interested readers can also find a longer pretraining run on the complete Project Gutenberg book corpus in [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)\n",
    "- Fortunately, we don't have to spend tens to hundreds of thousands of dollars to pretrain the model on a large pretraining corpus but can load the pretrained weights provided by OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {
    "id": "127ddbdb-3878-4669-9a39-d231fbdfb834"
   },
   "source": [
    "<span style=\"color:darkred\">\n",
    "  <ul>\n",
    "    <li>For an alternative way to load the weights from the Hugging Face Hub, see <a href=\"../02_alternative_weight_loading\">../02_alternative_weight_loading</a></li>\n",
    "    <ul>\n",
    "      <li>This is useful if:</li>\n",
    "      <ul>\n",
    "        <li>the weights are temporarily unavailable</li>\n",
    "        <li>a company VPN only permits downloads from the Hugging Face Hub but not from the OpenAI CDN, for example</li>\n",
    "        <li>you are having trouble with the TensorFlow installation (the original weights are stored in TensorFlow files)</li>\n",
    "      </ul>\n",
    "    </ul>\n",
    "    <li>The <a href=\"../02_alternative_weight_loading\">../02_alternative_weight_loading</a> code notebooks are replacements for the remainder of this section 5.5</li>\n",
    "  </ul>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cab892-a165-4f43-9601-f517bc212ab6",
   "metadata": {
    "id": "75cab892-a165-4f43-9601-f517bc212ab6"
   },
   "source": [
    "- First, some boilerplate code to download the files from OpenAI and load the weights into Python\n",
    "- Since OpenAI used [TensorFlow](https://www.tensorflow.org/), we will have to install and use TensorFlow for loading the weights; [tqdm](https://github.com/tqdm/tqdm) is a progress bar library\n",
    "- Uncomment and run the next cell to install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
    "outputId": "427efa52-1b98-4a6f-b86b-6228070547ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
    "outputId": "1bf7629e-0ff8-433b-ff10-1579218d6455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_epdQjkUjj6H",
   "metadata": {
    "id": "_epdQjkUjj6H"
   },
   "source": [
    "- the code for downloading GPT model: [gpt_download.py](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/gpt_download.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "nq8rdim-iBxQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nq8rdim-iBxQ",
    "outputId": "991e23b5-4117-4872-dcee-69a59fba3fdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7ce511794410>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    "    )\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
   "metadata": {
    "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed"
   },
   "outputs": [],
   "source": [
    "# Relative import from the gpt_download.py contained in this folder\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
   "metadata": {
    "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc"
   },
   "source": [
    "---\n",
    "\n",
    "**Note**\n",
    "\n",
    "- In very rare cases, the code cell above may result in a `zsh: illegal hardware instruction python` error, which could be due to a TensorFlow installation issue on your machine\n",
    "- A reader found that installing TensorFlow via `conda` solved the issue in this specific case, as mentioned [here](https://github.com/rasbt/LLMs-from-scratch/discussions/273#discussioncomment-12367888)\n",
    "- You can find more instructions in this supplementary [Python setup tutorial](https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences#option-2-using-conda)\n",
    "\n",
    "---\n",
    "\n",
    "- We can then download the model weights for the 124 million parameter model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
    "outputId": "8b101790-48fe-496b-805e-367ecf538d9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 157kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.73MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 206kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:35<00:00, 14.0MiB/s]\n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.50MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 2.19MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.53MiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
    "outputId": "b3662256-cbe3-483a-e8f6-9c1294fb78b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
    "outputId": "acb9f35f-c817-4e5d-9b43-bccb04ecdada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7Zy84NyQvOv_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Zy84NyQvOv_",
    "outputId": "75255b8a-e1c7-4359-c2a0-8d90ec371e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])]\n"
     ]
    }
   ],
   "source": [
    "print([d.keys() for d in params['blocks'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
    "outputId": "b8d23def-f301-4090-db99-0446695e8d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
   "metadata": {
    "id": "466e100c-294e-4afc-a70a-2f398ac4c104"
   },
   "source": [
    "- Alternatively, \"355M\", \"774M\", and \"1558M\" are also supported `model_size` arguments\n",
    "- The difference between these differently sized models is summarized in the figure below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
   "metadata": {
    "id": "20f19d32-5aae-4176-9f86-f391672c8f0d"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
   "metadata": {
    "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41"
   },
   "source": [
    "- Above, we loaded the 124M GPT-2 model weights into Python, however we still need to transfer them into our `GPTModel` instance\n",
    "- First, we initialize a new GPTModel instance\n",
    "- Note that the original GPT model initialized the linear layers for the query, key, and value matrices in the multi-head attention module with bias vectors, which is not required or recommended; however, to be able to load the weights correctly, we have to enable these too by setting `qkv_bias` to `True` in our implementation, too\n",
    "- We are also using the `1024` token context length that was used by the original GPT-2 model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
   "metadata": {
    "id": "9fef90dd-0654-4667-844f-08e28339ef7d"
   },
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
   "metadata": {
    "id": "272f29ac-8342-4b3d-a57d-9b0166ced314"
   },
   "source": [
    "- The next task is to assign the OpenAI weights to the corresponding weight tensors in our `GPTModel` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
   "metadata": {
    "id": "f9a92229-c002-49a6-8cfb-248297ad8296"
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
   "metadata": {
    "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1) # c_attn combines q_w, k_w and v_w for efficiency\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]) # g - gain/scale factor\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "qiF3NjJuwv0G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiF3NjJuwv0G",
    "outputId": "95f03aeb-d77a-460a-e9f0-8a1ccbf8a62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params['blocks'] type: <class 'list'>\n",
      "length: 12\n",
      "type of the first element: <class 'dict'>\n",
      "dict keys: [dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp']), dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])]\n"
     ]
    }
   ],
   "source": [
    "print(f\"params['blocks'] type: {type(params['blocks'])}\")\n",
    "print(f\"length: {len(params['blocks'])}\")\n",
    "print(f\"type of the first element: {type(params['blocks'][0])}\")\n",
    "print(f\"dict keys: {[d.keys() for d in params['blocks']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aBicvcXQ1DK9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBicvcXQ1DK9",
    "outputId": "2f20f21c-9352-444c-c1f7-fe07c923ac31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[attn] : dict_keys(['c_attn', 'c_proj'])\n",
      "\t[c_attn] : dict_keys(['b', 'w'])\n",
      "\t[c_proj] : dict_keys(['b', 'w'])\n",
      "[ln_1] : dict_keys(['b', 'g'])\n",
      "[ln_2] : dict_keys(['b', 'g'])\n"
     ]
    }
   ],
   "source": [
    "# combined attention and combined projection\n",
    "print(f\"[attn] : {params['blocks'][0]['attn'].keys()}\")\n",
    "print(f\"\\t[c_attn] : {params['blocks'][0]['attn']['c_attn'].keys()}\")\n",
    "print(f\"\\t[c_proj] : {params['blocks'][0]['attn']['c_proj'].keys()}\")\n",
    "print(f\"[ln_1] : {params['blocks'][0]['ln_1'].keys()}\")\n",
    "print(f\"[ln_2] : {params['blocks'][0]['ln_2'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "DmO-Y6gN4ef5",
   "metadata": {
    "id": "DmO-Y6gN4ef5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "F8lk3B8a0a5u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8lk3B8a0a5u",
    "outputId": "cd25ea7c-8dda-4026-87fa-30b9fd0e257a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768) (768, 768) (768, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][0][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "print(q_w.shape, k_w.shape, v_w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
   "metadata": {
    "id": "4f7472cb-54dc-4311-96d8-b2694f885cee"
   },
   "source": [
    "- If the model is loaded correctly, we can use it to generate new text using our previous `generate` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
    "outputId": "19ac91f0-9dc5-4c84-b62f-4b5879f5c2e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something happens\n",
      "\n",
      "This would remove you from a battle\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {
    "id": "6d079f98-a7c4-462e-8416-5a64f670861c"
   },
   "source": [
    "- We know that we loaded the model weights correctly because the model can generate coherent text; if we made even a small mistake, the model would not be able to do that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {
    "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44"
   },
   "source": [
    "- For an alternative way to load the weights from the Hugging Face Hub, see [../02_alternative_weight_loading](../02_alternative_weight_loading)\n",
    "- If you are interested in seeing how the GPT architecture compares to the Llama architecture (a popular LLM developed by Meta AI), see the bonus content at [../07_gpt_to_llama](../07_gpt_to_llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {
    "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {
    "id": "fc7ed189-a633-458c-bf12-4f70b42684b8"
   },
   "source": [
    "- See the [./gpt_train.py](./gpt_train.py) script, a self-contained script for training\n",
    "- The [./gpt_generate.py](./gpt_generate.py) script loads pretrained weights from OpenAI and generates text based on a prompt\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1ba6ac560ec6457d82f054fc3b0079b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2596b1e2f44d4e48a6ac0713925927af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_45448ce5b9d64bccbfc15fba04227b41",
       "max": 52,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_acd80fbfab1d4600b317b6e313651591",
       "value": 52
      }
     },
     "45448ce5b9d64bccbfc15fba04227b41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51a4591f715a492b8fb33f0fe06ed758": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a9ed58be584483ab586febe2e14144a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe385d377c2a44ea9e4f3ef99d80c231",
       "placeholder": "​",
       "style": "IPY_MODEL_1ba6ac560ec6457d82f054fc3b0079b8",
       "value": " 52/52 [00:01&lt;00:00,  9.76it/s]"
      }
     },
     "746a6d27fe6044b68a64aefbc305ebb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e2eb1320a0d1404f851f8483a4d288d3",
        "IPY_MODEL_2596b1e2f44d4e48a6ac0713925927af",
        "IPY_MODEL_5a9ed58be584483ab586febe2e14144a"
       ],
       "layout": "IPY_MODEL_fbf9d203376f49b29c9b54ca44f7a33b"
      }
     },
     "acd80fbfab1d4600b317b6e313651591": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e2eb1320a0d1404f851f8483a4d288d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_51a4591f715a492b8fb33f0fe06ed758",
       "placeholder": "​",
       "style": "IPY_MODEL_f05f787eff774df0a0a656c737fb8f98",
       "value": "Resolving data files: 100%"
      }
     },
     "f05f787eff774df0a0a656c737fb8f98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fbf9d203376f49b29c9b54ca44f7a33b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe385d377c2a44ea9e4f3ef99d80c231": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
